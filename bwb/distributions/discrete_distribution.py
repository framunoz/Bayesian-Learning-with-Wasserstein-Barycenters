import abc
from collections.abc import MutableMapping
from typing import TypeVar, Generic

import numpy as np
import torch
from PIL import Image
# noinspection PyPackageRequirements
from pyro.distributions import Categorical

from bwb.config import config

__all__ = [
    "DiscreteDistribution",
    "DistributionDraw",
    "DistributionDrawDataLoader",
]

TDistribution = TypeVar("TDistribution")


# noinspection PyAbstractClass


# noinspection PyAbstractClass
class DiscreteDistribution(Categorical):
    """
    Class that represent a discrete distribution, using de `Categorical` class provided by Pyro.
    """

    def __init__(
            self,
            pk, xk=None,
            validate_args=None,
    ):
        """
        Initializer.

        :param pk: Array of probabilities. If it is a Tensor type, the device shall be fixed by this parameter.
        :type pk: array_like
        :param xk: Support of the distribution. Optional.
        :type xk: array_like or None
        :param validate_args:
        """

        # Save pk and xk as tensor
        self.pk: torch.Tensor = torch.as_tensor(pk, dtype=config.dtype, device=config.device)

        xk = xk if xk is not None else range(len(self.pk))
        self.xk: torch.Tensor = torch.as_tensor(xk, device=config.device)

        if len(self.pk) != len(self.xk):
            raise ValueError(
                "The sizes of pk and xk does not coincide:"
                f" {len(self.pk)} != {len(self.xk)}")

        super().__init__(probs=self.pk, validate_args=validate_args)

    def enumerate_support_(self, expand=True):
        """Enumerates the original support ``xk`` and not its indices."""
        return self.xk[self.enumerate_support(expand)]

    def sample_(self, sample_shape=torch.Size([])):
        """Sample from the original support ``xk``."""
        return self.xk[self.sample(sample_shape)]


# noinspection PyAbstractClass
class DistributionDraw(DiscreteDistribution):
    """Distribution generated by a drawing, which is represented by a matrix."""

    def __init__(
            self,
            weights,
            shape,
    ):
        """
        Initialiser.

        :param weights: The weights of the distribution.
        :param shape: The shape of the image that represents the distribution.
        """

        # Get the shape information
        self.shape = shape
        if len(self.shape) != 2:
            raise ValueError("The shape must have dimension 2.")
        n, m = self.shape
        if n * m != len(weights):
            raise ValueError("The weights must be equals to n * m, where shape=(n, m).")

        # Get the support as coordinates
        indx = torch.arange(n * m, device=config.device).reshape(-1, 1)
        support = torch.cat((indx // m, indx % m), 1)

        super(DistributionDraw, self).__init__(pk=weights, xk=support)

    @classmethod
    def from_array(
            cls,
            grayscale,
    ):

        # Save the grayscales for create images
        grayscale: torch.Tensor = torch.as_tensor(
            grayscale,
            dtype=torch.uint8,  # Use uint8 for images
            device=config.device
        )

        # Get the shape information
        shape = tuple(grayscale.shape)
        if len(shape) != 2:
            raise ValueError("The 'grayscale' tensor must have dimension 2.")

        # Get the weights from the grayscale
        weights: torch.Tensor = grayscale / 255
        weights /= torch.sum(weights)
        weights = weights.reshape((-1,))

        return cls(weights=weights, shape=shape)

    @property
    def grayscale(self) -> np.ndarray:
        """A matrix representing the gray scale of the image."""
        grayscale_ = self.pk / torch.max(self.pk) * 255
        grayscale_ = grayscale_.reshape(self.shape).clone().detach()
        return grayscale_.to(torch.uint8).cpu().numpy()

    @property
    def image(self) -> Image.Image:
        """Representation of the Image.

        :return: An PIL.Image.Image instance.
        """
        return Image.fromarray(255 - self.grayscale)

    def __repr__(self):
        return type(self).__name__ + f"(shape: {self.shape})"

    def _repr_png_(self):
        """iPython display hook support

        :returns: png version of the image as bytes
        """
        # noinspection PyUnresolvedReferences,PyProtectedMember
        return self.image._repr_png_()


class BaseDistributionDataLoader(MutableMapping, Generic[TDistribution], abc.ABC):
    """
    Base class for DataLoaders. It is a ``MutableMapping`` that creates instances of distributions in a 'lazy' way,
    saving computation time. It ends up representing several distributions from a tensor with the corresponding weights.
    """

    def __init__(
            self,
            probs_tensor,
    ):
        # Set the probs_tensor
        self.probs_tensor: torch.Tensor = torch.as_tensor(probs_tensor, device=config.device)
        _n_probs = len(self.probs_tensor)
        probs_tensor_sum = self.probs_tensor.sum(dim=1)
        if not (probs_tensor_sum == torch.ones_like(probs_tensor_sum)).all():
            raise ValueError("The sum over the dim 1 of the tensor probs_tensor must all be 1.")

        # Set the tensor of log-probabilities
        self.logits_tensor = torch.logit(self.probs_tensor, config.eps)

        # And define the dictionary to wrap
        self._models: dict[int, TDistribution] = {i: None for i in range(_n_probs)}

    @abc.abstractmethod
    def _create_distribution_instance(self, index) -> TDistribution:
        """To use template pattern on __get_item__"""
        raise NotImplementedError("Must implement method '_create_distribution_instance'.")

    def __getitem__(self, item: int) -> TDistribution:
        if self._models[item] is None:
            self._models[item] = self._create_distribution_instance(item)
        return self._models[item]

    def __setitem__(self, key: int, value: TDistribution):
        self._models[key] = value

    def __delitem__(self, key: int):
        del self._models[key]

    def __iter__(self):
        return self._models.__iter__()

    def __contains__(self, item):
        return item in self._models

    def __len__(self) -> int:
        return len(self._models)


class DiscreteDistributionDataLoader(BaseDistributionDataLoader[DiscreteDistribution]):
    """
    DataLoader for the ``DiscreteDistributions``.
    """

    def _create_distribution_instance(self, index: int) -> DiscreteDistribution:
        return DiscreteDistribution(self.probs_tensor[index])


# noinspection PyAttributeOutsideInit
class DistributionDrawDataLoader(BaseDistributionDataLoader[DistributionDraw]):
    """A class of type ``MutableMapping`` that wraps a dictionary. It stores information from probability arrays and
     logits. This class can be thought of as using the flyweight pattern, so as not to take up too much instantiation
     time, or if an instance already exists, to reuse it."""

    def __init__(
            self,
            models_array,
            shape,
            floor=0,
    ):
        """
        :type models_array: scalar or sequence or arraylike

        :param models_array: Arreglo de modelos.
        :type shape: tuple[int, int]
        :param shape: Dimensiones de las imágenes originales.
        :type floor: int
        :param floor: Número que funciona como valor mínimo de las imágenes.
        """
        self.floor: int = int(floor)

        # Setting the shape
        self.shape = shape

        # Setting the tensor of probabilities
        probs_tensor = torch.tensor(models_array, device=config.device)
        if self.floor != 0:
            probs_tensor = torch.min(probs_tensor, self.floor)
        probs_tensor = probs_tensor / 255
        probs_tensor = probs_tensor / torch.sum(probs_tensor, 1).reshape(-1, 1)

        super(DistributionDrawDataLoader, self).__init__(probs_tensor=probs_tensor)

    def _create_distribution_instance(self, index) -> DistributionDraw:
        return DistributionDraw(self.probs_tensor[index], self.shape)
