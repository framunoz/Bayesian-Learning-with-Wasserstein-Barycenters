{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/codeProjects/pythonProjects/Bayesian-Learning-with-Wasserstein-Barycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import typing as t\n",
    "from bwb.utils import _DistributionT\n",
    "import collections as c\n",
    "\n",
    "\n",
    "class DistributionSampler(abc.ABC, t.Generic[_DistributionT]):\n",
    "    r\"\"\"\n",
    "    Base class for distributions that sampling other distributions. i.e. it represents a distribution :math:`\\Lambda(dm) \\in \\mathcal{P}(\\mathcal{M)}`, where :math:`\\mathcal{M}` is the set of models.\n",
    "    \"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def draw(self, *args, **kwargs) -> _DistributionT:\n",
    "        \"\"\"Draw a sample.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def rvs(self, size=1, *args, **kwargs) -> t.Sequence[_DistributionT]:\n",
    "        \"\"\"Samples as many distributions as the ``size`` parameter indicates.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteDistributionSampler(DistributionSampler[_DistributionT]):\n",
    "    r\"\"\"\n",
    "    Base class for distributions that have a discrete set of models. i.e. where the set of models is :math:`|\\mathcal{M}| < +\\infty`.\n",
    "\n",
    "    As the support is discrete, the distribution can be represented as a vector of probabilities, and therefore, the sampling process is reduced to drawing an index from a multinomial distribution. This property allows to save the samples and the number of times each model has been sampled, to get statistics about the sampling process.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, save_samples: bool = False):\n",
    "        self.save_samples = save_samples\n",
    "        self.samples_history: list[int] = []\n",
    "        self.samples_counter: c.Counter[int] = c.Counter()\n",
    "        self._models: dict[int, _DistributionT] = {}\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _draw(self, *args, **kwargs) -> tuple[_DistributionT, int]:\n",
    "        \"\"\"To use template pattern on the draw method.\"\"\"\n",
    "        ...\n",
    "\n",
    "    # @abc.abstractmethod\n",
    "    def draw(self, *args, **kwargs) -> _DistributionT:\n",
    "        \"\"\"Draw a sample.\"\"\"\n",
    "        to_return, i = self._draw(*args, **kwargs)\n",
    "        if self.save_samples:  # Register the sample\n",
    "            self.samples_history.append(i)\n",
    "            self.samples_counter[i] += 1\n",
    "        return to_return\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _rvs(\n",
    "        self, size=1, *args, **kwargs\n",
    "    ) -> tuple[t.Sequence[_DistributionT], list[int]]:\n",
    "        \"\"\"Samples as many distributions as the ``size`` parameter indicates.\"\"\"\n",
    "        ...\n",
    "\n",
    "    # @abc.abstractmethod\n",
    "    def rvs(self, size=1, *args, **kwargs) -> t.Sequence[_DistributionT]:\n",
    "        \"\"\"Samples as many distributions as the ``size`` parameter indicates.\"\"\"\n",
    "        to_return, list_indices = self._rvs(size, *args, **kwargs)\n",
    "        if self.save_samples:  # Register the samples\n",
    "            self.samples_history.extend(list_indices)\n",
    "            self.samples_counter.update(list_indices)\n",
    "        return to_return\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_model(self, i: int) -> _DistributionT:\n",
    "        \"\"\"Get the model with index i.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        to_return = self.__class__.__name__\n",
    "\n",
    "        if self.save_samples:\n",
    "            to_return += f\"(samples={len(self.samples_history)})\"\n",
    "\n",
    "        return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quickdraw_dataset import QuickDraw\n",
    "import torchvision.transforms as T\n",
    "from pathlib import Path\n",
    "from bwb.distributions import DistributionDraw\n",
    "import torch\n",
    "from bwb.config import config\n",
    "\n",
    "ds = QuickDraw(\n",
    "    Path(\"./data\"),\n",
    "    category=\"face\",\n",
    "    download=True,\n",
    "    transform=T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Lambda(lambda x: x.squeeze()),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "ds_ = QuickDraw(\n",
    "    Path(\"./data\"),\n",
    "    category=\"face\",\n",
    "    download=True,\n",
    "    transform=T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Lambda(lambda x: x.squeeze()),\n",
    "        T.Lambda(lambda x: DistributionDraw.from_grayscale_weights(x)),\n",
    "    ]),\n",
    ")\n",
    "first_face = ds_[0][0]\n",
    "data = first_face.sample((100,)).reshape(1, -1)\n",
    "data.shape\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwb.utils import _ArrayLike\n",
    "\n",
    "\n",
    "@t.runtime_checkable\n",
    "class DiscreteModelsSet(t.Protocol, t.Generic[_DistributionT]):\n",
    "    \"\"\"\n",
    "    Protocol for classes that are a set of models with a discrete support.\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_probability(self, data: _ArrayLike, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the probabilities of the data given the models.\n",
    "\n",
    "        :param data: The data to compute the probabilities.\n",
    "        :return: A tensor with the probabilities.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def get(self, i: int, **kwargs) -> _DistributionT:\n",
    "        \"\"\"Get the model at the index ``i``.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Get the number of models.\"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "for num_workers in range(0, mp.cpu_count() + 1, 2):\n",
    "    train_loader = DataLoader(\n",
    "        ds,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        batch_size=256,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    start = time()\n",
    "    for epoch in range(1, 3):\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            pass\n",
    "    end = time()\n",
    "    print(\n",
    "        \"Finish with:{:.4f} second, num_workers={}\".format(\n",
    "            end - start, num_workers\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from bwb.config import config\n",
    "from bwb.utils import _ArrayLike\n",
    "import bwb.distributions as dist\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "# Method for the class ``QuickDraw``.\n",
    "def compute_probability(self, data: _ArrayLike, **kwargs) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the probabilities of the data given the models.\n",
    "\n",
    "    :param data: The data to compute the probabilities.\n",
    "    :return: A tensor with the probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        self,\n",
    "        batch_size=kwargs.get(\"batch_size\", 1024),\n",
    "        shuffle=False,\n",
    "        num_workers=kwargs.get(\"num_workers\", mp.cpu_count()),\n",
    "    )\n",
    "\n",
    "    likelihoods = []\n",
    "\n",
    "    for features, _ in dataloader:\n",
    "        features = features.to(config.device)\n",
    "        features = features.reshape(features.size(0), -1)\n",
    "        features = features / features.sum(dim=1, keepdim=True)\n",
    "        evaluations = torch.take_along_dim(features, data, 1)\n",
    "        likelihood = torch.exp(evaluations.sum(dim=1))\n",
    "\n",
    "        likelihoods.append(likelihood)\n",
    "\n",
    "    likelihood_cache = torch.cat(likelihoods, dim=0)\n",
    "\n",
    "    probabilities = likelihood_cache / likelihood_cache.sum()\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "# Method for the class ``QuickDraw``.\n",
    "def get(self, i: int, **kwargs) -> dist.DistributionDraw:\n",
    "    \"\"\"Get the model at the index ``i``.\"\"\"\n",
    "    return dist.DistributionDraw.from_grayscale_weights(self[i][0])\n",
    "\n",
    "\n",
    "# Add the methods to the class.\n",
    "QuickDraw.compute_probability = compute_probability\n",
    "QuickDraw.get = get\n",
    "\n",
    "ds.compute_probability(data.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds._get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(ds, batch_size=2**18, shuffle=False)\n",
    "\n",
    "features, labels = next(iter(dataloader))\n",
    "\n",
    "# features = features.to(\"cpu\")\n",
    "\n",
    "# features /= features.sum(dim=1, keepdim=True)\n",
    "\n",
    "torch.take_along_dim(features, data, 1)\n",
    "\n",
    "# features.sum(dim=1).shape\n",
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwb.utils import _ArrayLike\n",
    "import torch\n",
    "from bwb.config import config\n",
    "import bwb.distributions as dist\n",
    "\n",
    "\n",
    "def _set_generator(seed=None, device=\"cpu\") -> torch.Generator:\n",
    "    gen = torch.Generator(device=device)\n",
    "    if seed is None:\n",
    "        gen.seed()\n",
    "        return gen\n",
    "    gen.manual_seed(seed)\n",
    "    return gen\n",
    "\n",
    "\n",
    "class ExplicitPosteriorSampler(\n",
    "    DiscreteDistributionSampler[dist.DistributionDraw]\n",
    "):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._fitted = False\n",
    "        self.total_time = 0.0\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        data: _ArrayLike,\n",
    "        models: DiscreteModelsSet[dist.DistributionDraw],\n",
    "        batch_size: int = 256,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Fit the posterior distribution.\n",
    "\n",
    "        :param data: The data to fit the posterior.\n",
    "        :param models: The models to fit the posterior.\n",
    "        :param batch_size: The batch size to compute the probabilities.\n",
    "        :return: The fitted posterior.\n",
    "        \"\"\"\n",
    "        assert isinstance(\n",
    "            models, DiscreteModelsSet\n",
    "        ), \"The models must be a DiscreteModelsSet.\"\n",
    "\n",
    "        self.data_: torch.Tensor = torch.as_tensor(data, device=config.device)\n",
    "        self.models_: DiscreteModelsSet[dist.DistributionDraw] = models\n",
    "        self.models_index_: torch.Tensor = torch.arange(\n",
    "            len(models), device=config.device\n",
    "        )\n",
    "\n",
    "        data = self.data_.reshape(1, -1)\n",
    "\n",
    "        self.probabilities_: torch.Tensor = models._compute_probability(\n",
    "            data, batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        self.support_ = self.models_index_[self.probabilities_ > 0]\n",
    "\n",
    "        self._fitted = True\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_model(self, i: int) -> dist.DistributionDraw:\n",
    "        \"\"\"Get the model with index i.\"\"\"\n",
    "        if self._models.get(i) is None:\n",
    "            self._models[i] = self.models_._get(i)\n",
    "        return self._models[i]\n",
    "\n",
    "    def _draw(self, seed=None, *args, **kwargs) -> tuple[_DistributionT, int]:\n",
    "        rng: torch.Generator = _set_generator(seed=seed, device=config.device)\n",
    "\n",
    "        i = torch.multinomial(\n",
    "            input=self.probabilities_, num_samples=1, generator=rng\n",
    "        ).item()\n",
    "        i = int(i)\n",
    "        return self.get_model(i), i\n",
    "\n",
    "    def _rvs(\n",
    "        self, size=1, seed=None, *args, **kwargs\n",
    "    ) -> tuple[t.Sequence[_DistributionT], list[int]]:\n",
    "        rng: torch.Generator = _set_generator(seed=seed, device=config.device)\n",
    "\n",
    "        indices = torch.multinomial(\n",
    "            input=self.probabilities_,\n",
    "            num_samples=size,\n",
    "            replacement=True,\n",
    "            generator=rng,\n",
    "        )\n",
    "        indices = indices.tolist()\n",
    "        return [self.get_model(i) for i in indices], indices\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        to_return = self.__class__.__name__\n",
    "\n",
    "        if not self._fitted:\n",
    "            to_return += \"()\"\n",
    "            return to_return\n",
    "\n",
    "        to_return += \"(\"\n",
    "        to_return += f\"n_data={len(self.data_)}, \"\n",
    "        to_return += f\"n_models={len(self.models_)}, \"\n",
    "        to_return += f\"n_support={len(self.support_)}\"\n",
    "        to_return += \")\"\n",
    "\n",
    "        return to_return\n",
    "\n",
    "\n",
    "posterior = ExplicitPosteriorSampler(save_samples=True)\n",
    "\n",
    "posterior.fit(data, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior._models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
