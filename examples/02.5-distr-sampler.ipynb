{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "%cd ~/codeProjects/pythonProjects/Bayesian-Learning-with-Wasserstein-Barycenters"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "import abc\n",
    "import typing as t\n",
    "from bwb.utils import _DistributionT\n",
    "import collections as c\n",
    "\n",
    "\n",
    "class DistributionSampler(abc.ABC, t.Generic[_DistributionT]):\n",
    "    r\"\"\"\n",
    "    Base class for distributions that sampling other distributions. i.e. it represents a distribution :math:`\\Lambda(dm) \\in \\mathcal{P}(\\mathcal{M)}`, where :math:`\\mathcal{M}` is the set of models. \n",
    "    \"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def draw(self, *args, **kwargs) -> _DistributionT:\n",
    "        \"\"\"Draw a sample.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def rvs(self, size=1, *args, **kwargs) -> t.Sequence[_DistributionT]:\n",
    "        \"\"\"Samples as many distributions as the ``size`` parameter indicates.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "class DiscreteDistributionSampler(DistributionSampler[_DistributionT]):\n",
    "    r\"\"\"\n",
    "    Base class for distributions that have a discrete set of models. i.e. where the set of models is :math:`|\\mathcal{M}| < +\\infty`. \n",
    "    \n",
    "    As the support is discrete, the distribution can be represented as a vector of probabilities, and therefore, the sampling process is reduced to drawing an index from a multinomial distribution. This property allows to save the samples and the number of times each model has been sampled, to get statistics about the sampling process.\n",
    "    \"\"\"\n",
    "    def __init__(self, save_samples: bool = False):\n",
    "        self.save_samples = save_samples\n",
    "        self.samples_history: list[int] = []\n",
    "        self.samples_counter: c.Counter[int] = c.Counter()\n",
    "        self._models: dict[int, _DistributionT] = {}\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _draw(self, *args, **kwargs) -> tuple[_DistributionT, int]:\n",
    "        \"\"\"To use template pattern on the draw method.\"\"\"\n",
    "        ...\n",
    "\n",
    "    # @abc.abstractmethod\n",
    "    def draw(self, *args, **kwargs) -> _DistributionT:\n",
    "        \"\"\"Draw a sample.\"\"\"\n",
    "        to_return, i = self._draw(*args, **kwargs)\n",
    "        if self.save_samples:  # Register the sample\n",
    "            self.samples_history.append(i)\n",
    "            self.samples_counter[i] += 1\n",
    "        return to_return\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _rvs(self, size=1, *args, **kwargs) -> tuple[t.Sequence[_DistributionT], list[int]]:\n",
    "        \"\"\"Samples as many distributions as the ``size`` parameter indicates.\"\"\"\n",
    "        ...\n",
    "\n",
    "    # @abc.abstractmethod\n",
    "    def rvs(self, size=1, *args, **kwargs) -> t.Sequence[_DistributionT]:\n",
    "        \"\"\"Samples as many distributions as the ``size`` parameter indicates.\"\"\"\n",
    "        to_return, list_indices = self._rvs(size, *args, **kwargs)\n",
    "        if self.save_samples:  # Register the samples\n",
    "            self.samples_history.extend(list_indices)\n",
    "            self.samples_counter.update(list_indices)\n",
    "        return to_return\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def get_model(self, i: int) -> _DistributionT:\n",
    "        \"\"\"Get the model with index i.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        to_return = self.__class__.__name__\n",
    "\n",
    "        if self.save_samples:\n",
    "            to_return += f\"(samples={len(self.samples_history)})\"\n",
    "\n",
    "        return to_return"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "from quickdraw_dataset import QuickDraw\n",
    "import torchvision.transforms as T\n",
    "from pathlib import Path\n",
    "from bwb.distributions import DistributionDraw\n",
    "import torch\n",
    "from bwb.config import config\n",
    "\n",
    "ds = QuickDraw(\n",
    "    Path(\"./data\"),\n",
    "    category=\"face\",\n",
    "    download=True,\n",
    "    transform=T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Lambda(lambda x: x.squeeze()),\n",
    "    ])\n",
    ")\n",
    "\n",
    "ds_ = QuickDraw(\n",
    "    Path(\"./data\"),\n",
    "    category=\"face\",\n",
    "    download=True,\n",
    "    transform=T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Lambda(lambda x: x.squeeze()),\n",
    "        T.Lambda(lambda x: DistributionDraw.from_grayscale_weights(x))\n",
    "    ])\n",
    ")\n",
    "first_face = ds_[0][0]\n",
    "data = first_face.sample((100,)).reshape(1, -1)\n",
    "data.shape\n",
    "len(ds)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "from bwb.utils import _ArrayLike\n",
    "\n",
    "@t.runtime_checkable\n",
    "class DiscreteModelsSet(t.Protocol, t.Generic[_DistributionT]):\n",
    "    \"\"\"\n",
    "    Protocol for classes that are a set of models with a discrete support.\n",
    "    \"\"\"\n",
    "    def compute_probability(self, data: _ArrayLike, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the probabilities of the data given the models.\n",
    "        \n",
    "        :param data: The data to compute the probabilities.\n",
    "        :return: A tensor with the probabilities.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def get(self, i: int, **kwargs) -> _DistributionT:\n",
    "        \"\"\"Get the model at the index ``i``.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Get the number of models.\"\"\"\n",
    "        ..."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "from time import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "mp.cpu_count()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "from torch.utils.data import DataLoader\n",
    "for num_workers in range(0, mp.cpu_count()+1, 2):  \n",
    "    train_loader = DataLoader(ds,shuffle=True,num_workers=num_workers,batch_size=256,pin_memory=True)\n",
    "    start = time()\n",
    "    for epoch in range(1, 3):\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            pass\n",
    "    end = time()\n",
    "    print(\"Finish with:{:.4f} second, num_workers={}\".format(end - start, num_workers))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from bwb.config import config\n",
    "from bwb.utils import _ArrayLike\n",
    "import bwb.distributions as dist\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Method for the class ``QuickDraw``.\n",
    "def compute_probability(self, data: _ArrayLike, **kwargs) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the probabilities of the data given the models.\n",
    "    \n",
    "    :param data: The data to compute the probabilities.\n",
    "    :return: A tensor with the probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    dataloader = DataLoader(self, batch_size=kwargs.get(\"batch_size\", 1024), shuffle=False, num_workers=kwargs.get(\"num_workers\", mp.cpu_count()))\n",
    "\n",
    "    likelihoods = []\n",
    "\n",
    "    for features, _ in dataloader:\n",
    "        features = features.to(config.device)\n",
    "        features = features.reshape(features.size(0), -1)\n",
    "        features = features / features.sum(dim=1, keepdim=True)\n",
    "        evaluations = torch.take_along_dim(features, data, 1)\n",
    "        likelihood = torch.exp(evaluations.sum(dim=1))\n",
    "\n",
    "        likelihoods.append(likelihood)\n",
    "\n",
    "    likelihood_cache = torch.cat(likelihoods, dim=0)\n",
    "\n",
    "    probabilities = likelihood_cache / likelihood_cache.sum()\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "# Method for the class ``QuickDraw``.\n",
    "def get(self, i: int, **kwargs) -> dist.DistributionDraw:\n",
    "    \"\"\"Get the model at the index ``i``.\"\"\"\n",
    "    return dist.DistributionDraw.from_grayscale_weights(self[i][0])\n",
    "\n",
    "# Add the methods to the class.\n",
    "QuickDraw.compute_probability = compute_probability\n",
    "QuickDraw.get = get\n",
    "\n",
    "ds.compute_probability(data.reshape(1, -1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "ds._get(0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "dataloader = DataLoader(ds, batch_size=2 ** 18, shuffle=False)\n",
    "\n",
    "features, labels = next(iter(dataloader))\n",
    "\n",
    "# features = features.to(\"cpu\")\n",
    "\n",
    "# features /= features.sum(dim=1, keepdim=True)\n",
    "\n",
    "torch.take_along_dim(features, data, 1)\n",
    "\n",
    "# features.sum(dim=1).shape\n",
    "len(dataloader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "source": [
    "len(dataloader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "source": [
    "from bwb.utils import _ArrayLike\n",
    "import torch\n",
    "from bwb.config import config\n",
    "import bwb.distributions as dist\n",
    "\n",
    "\n",
    "def _set_generator(seed=None, device=\"cpu\") -> torch.Generator:\n",
    "    gen = torch.Generator(device=device)\n",
    "    if seed is None:\n",
    "        gen.seed()\n",
    "        return gen\n",
    "    gen.manual_seed(seed)\n",
    "    return gen\n",
    "\n",
    "\n",
    "\n",
    "class ExplicitPosteriorSampler(DiscreteDistributionSampler[dist.DistributionDraw]):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._fitted = False\n",
    "        self.total_time = 0.0\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            data: _ArrayLike,\n",
    "            models: DiscreteModelsSet[dist.DistributionDraw],\n",
    "            batch_size: int = 256,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Fit the posterior distribution.\n",
    "\n",
    "        :param data: The data to fit the posterior.\n",
    "        :param models: The models to fit the posterior.\n",
    "        :param batch_size: The batch size to compute the probabilities.\n",
    "        :return: The fitted posterior.\n",
    "        \"\"\"\n",
    "        assert isinstance(models, DiscreteModelsSet), \"The models must be a DiscreteModelsSet.\"\n",
    "\n",
    "\n",
    "        self.data_: torch.Tensor = torch.as_tensor(data, device=config.device)\n",
    "        self.models_: DiscreteModelsSet[dist.DistributionDraw] = models\n",
    "        self.models_index_: torch.Tensor = torch.arange(len(models), device=config.device)\n",
    "\n",
    "        data = self.data_.reshape(1, -1)\n",
    "\n",
    "        self.probabilities_: torch.Tensor = models._compute_probability(data, batch_size=batch_size)\n",
    "\n",
    "        self.support_ = self.models_index_[self.probabilities_ > 0]\n",
    "\n",
    "        \n",
    "        self._fitted = True\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def get_model(self, i: int) -> dist.DistributionDraw:\n",
    "        \"\"\"Get the model with index i.\"\"\"\n",
    "        if self._models.get(i) is None:\n",
    "            self._models[i] = self.models_._get(i)\n",
    "        return self._models[i]\n",
    "\n",
    "    def _draw(self, seed=None, *args, **kwargs) -> tuple[_DistributionT, int]:\n",
    "        rng: torch.Generator = _set_generator(seed=seed, device=config.device)\n",
    "\n",
    "        i = torch.multinomial(input=self.probabilities_, num_samples=1, generator=rng).item()\n",
    "        i = int(i)\n",
    "        return self.get_model(i), i\n",
    "\n",
    "    def _rvs(self, size=1, seed=None, *args, **kwargs) -> tuple[t.Sequence[_DistributionT], list[int]]:\n",
    "        rng: torch.Generator = _set_generator(seed=seed, device=config.device)\n",
    "\n",
    "        indices = torch.multinomial(input=self.probabilities_, num_samples=size, replacement=True, generator=rng)\n",
    "        indices = indices.tolist()\n",
    "        return [self.get_model(i) for i in indices], indices\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        to_return = self.__class__.__name__\n",
    "\n",
    "        if not self._fitted:\n",
    "            to_return += \"()\"\n",
    "            return to_return\n",
    "\n",
    "        to_return += \"(\"\n",
    "        to_return += f\"n_data={len(self.data_)}, \"\n",
    "        to_return += f\"n_models={len(self.models_)}, \"\n",
    "        to_return += f\"n_support={len(self.support_)}\"\n",
    "        to_return += \")\"\n",
    "\n",
    "        return to_return\n",
    "        \n",
    "\n",
    "\n",
    "posterior = ExplicitPosteriorSampler(save_samples=True)\n",
    "\n",
    "posterior.fit(data, ds)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "source": [
    "posterior.draw()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "posterior._models"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
