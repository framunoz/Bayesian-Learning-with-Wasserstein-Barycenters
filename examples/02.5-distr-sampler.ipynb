{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fmunoz/codeProjects/pythonProjects/Bayesian-Learning-with-Wasserstein-Barycenters\n"
     ]
    }
   ],
   "source": [
    "%cd ~/codeProjects/pythonProjects/Bayesian-Learning-with-Wasserstein-Barycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import typing as t\n",
    "from bwb.utils import _DistributionT\n",
    "import collections as c\n",
    "\n",
    "\n",
    "class DistributionSampler(abc.ABC, t.Generic[_DistributionT]):\n",
    "    r\"\"\"\n",
    "    Base class for distributions that sampling other distributions. i.e. it represents a distribution :math:`\\Lambda(dm) \\in \\mathcal{P}(\\mathcal{M)}`, where :math:`\\mathcal{M}` is the set of models. \n",
    "    \"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def draw(self, *args, **kwargs) -> _DistributionT:\n",
    "        \"\"\"Draw a sample.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def rvs(self, size=1, *args, **kwargs) -> t.Sequence[_DistributionT]:\n",
    "        \"\"\"Samples as many distributions as the ``size`` parameter indicates.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteDistributionSampler(DistributionSampler[_DistributionT]):\n",
    "    r\"\"\"\n",
    "    Base class for distributions that have a discrete set of models. i.e. where the set of models is :math:`|\\mathcal{M}| < +\\infty`. \n",
    "    \n",
    "    As the support is discrete, the distribution can be represented as a vector of probabilities, and therefore, the sampling process is reduced to drawing an index from a multinomial distribution. This property allows to save the samples and the number of times each model has been sampled, to get statistics about the sampling process.\n",
    "    \"\"\"\n",
    "    def __init__(self, save_samples: bool = False):\n",
    "        self.save_samples = save_samples\n",
    "        self.samples_history: list[int] = []\n",
    "        self.samples_counter: c.Counter[int] = c.Counter()\n",
    "        self._models: dict[int, _DistributionT] = {}\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _draw(self, *args, **kwargs) -> tuple[_DistributionT, int]:\n",
    "        \"\"\"To use template pattern on the draw method.\"\"\"\n",
    "        ...\n",
    "\n",
    "    # @abc.abstractmethod\n",
    "    def draw(self, *args, **kwargs) -> _DistributionT:\n",
    "        \"\"\"Draw a sample.\"\"\"\n",
    "        to_return, i = self._draw(*args, **kwargs)\n",
    "        if self.save_samples:  # Register the sample\n",
    "            self.samples_history.append(i)\n",
    "            self.samples_counter[i] += 1\n",
    "        return to_return\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _rvs(self, size=1, *args, **kwargs) -> tuple[t.Sequence[_DistributionT], list[int]]:\n",
    "        \"\"\"Samples as many distributions as the ``size`` parameter indicates.\"\"\"\n",
    "        ...\n",
    "\n",
    "    # @abc.abstractmethod\n",
    "    def rvs(self, size=1, *args, **kwargs) -> t.Sequence[_DistributionT]:\n",
    "        \"\"\"Samples as many distributions as the ``size`` parameter indicates.\"\"\"\n",
    "        to_return, list_indices = self._rvs(size, *args, **kwargs)\n",
    "        if self.save_samples:  # Register the samples\n",
    "            self.samples_history.extend(list_indices)\n",
    "            self.samples_counter.update(list_indices)\n",
    "        return to_return\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def get_model(self, i: int) -> _DistributionT:\n",
    "        \"\"\"Get the model with index i.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        to_return = self.__class__.__name__\n",
    "\n",
    "        if self.save_samples:\n",
    "            to_return += f\"(samples={len(self.samples_history)})\"\n",
    "\n",
    "        return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161666"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quickdraw_dataset import QuickDraw\n",
    "import torchvision.transforms as T\n",
    "from pathlib import Path\n",
    "from bwb.distributions import DistributionDraw\n",
    "import torch\n",
    "from bwb.config import config\n",
    "\n",
    "ds = QuickDraw(\n",
    "    Path(\"./data\"),\n",
    "    category=\"face\",\n",
    "    download=True,\n",
    "    transform=T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Lambda(lambda x: x.squeeze()),\n",
    "    ])\n",
    ")\n",
    "\n",
    "ds_ = QuickDraw(\n",
    "    Path(\"./data\"),\n",
    "    category=\"face\",\n",
    "    download=True,\n",
    "    transform=T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Lambda(lambda x: x.squeeze()),\n",
    "        T.Lambda(lambda x: DistributionDraw.from_grayscale_weights(x))\n",
    "    ])\n",
    ")\n",
    "first_face = ds_[0][0]\n",
    "data = first_face.sample((100,)).reshape(1, -1)\n",
    "data.shape\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwb.utils import _ArrayLike\n",
    "\n",
    "@t.runtime_checkable\n",
    "class DiscreteModelsSet(t.Protocol, t.Generic[_DistributionT]):\n",
    "    \"\"\"\n",
    "    Protocol for classes that are a set of models with a discrete support.\n",
    "    \"\"\"\n",
    "    def compute_probability(self, data: _ArrayLike, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the probabilities of the data given the models.\n",
    "        \n",
    "        :param data: The data to compute the probabilities.\n",
    "        :return: A tensor with the probabilities.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def get(self, i: int, **kwargs) -> _DistributionT:\n",
    "        \"\"\"Get the model at the index ``i``.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Get the number of models.\"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:30.3069 second, num_workers=0\n",
      "Finish with:17.1369 second, num_workers=2\n",
      "Finish with:9.6121 second, num_workers=4\n",
      "Finish with:7.4786 second, num_workers=6\n",
      "Finish with:6.2474 second, num_workers=8\n",
      "Finish with:5.2778 second, num_workers=10\n",
      "Finish with:5.1597 second, num_workers=12\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "for num_workers in range(0, mp.cpu_count()+1, 2):  \n",
    "    train_loader = DataLoader(ds,shuffle=True,num_workers=num_workers,batch_size=256,pin_memory=True)\n",
    "    start = time()\n",
    "    for epoch in range(1, 3):\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            pass\n",
    "    end = time()\n",
    "    print(\"Finish with:{:.4f} second, num_workers={}\".format(end - start, num_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.8912e-06, 6.4909e-06, 6.4600e-06,  ..., 6.6061e-06, 6.3055e-06,\n",
       "        5.7960e-06], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from bwb.config import config\n",
    "from bwb.utils import _ArrayLike\n",
    "import bwb.distributions as dist\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Method for the class ``QuickDraw``.\n",
    "def compute_probability(self, data: _ArrayLike, **kwargs) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the probabilities of the data given the models.\n",
    "    \n",
    "    :param data: The data to compute the probabilities.\n",
    "    :return: A tensor with the probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    dataloader = DataLoader(self, batch_size=kwargs.get(\"batch_size\", 1024), shuffle=False, num_workers=kwargs.get(\"num_workers\", mp.cpu_count()))\n",
    "\n",
    "    likelihoods = []\n",
    "\n",
    "    for features, _ in dataloader:\n",
    "        features = features.to(config.device)\n",
    "        features = features.reshape(features.size(0), -1)\n",
    "        features = features / features.sum(dim=1, keepdim=True)\n",
    "        evaluations = torch.take_along_dim(features, data, 1)\n",
    "        likelihood = torch.exp(evaluations.sum(dim=1))\n",
    "\n",
    "        likelihoods.append(likelihood)\n",
    "\n",
    "    likelihood_cache = torch.cat(likelihoods, dim=0)\n",
    "\n",
    "    probabilities = likelihood_cache / likelihood_cache.sum()\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "# Method for the class ``QuickDraw``.\n",
    "def get(self, i: int, **kwargs) -> dist.DistributionDraw:\n",
    "    \"\"\"Get the model at the index ``i``.\"\"\"\n",
    "    return dist.DistributionDraw.from_grayscale_weights(self[i][0])\n",
    "\n",
    "# Add the methods to the class.\n",
    "QuickDraw.compute_probability = compute_probability\n",
    "QuickDraw.get = get\n",
    "\n",
    "ds.compute_probability(data.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvUlEQVR4nJ3ST0iTcRzH8fezP200iB6NtFJGMXxyiSQRZBgUMRKiiJrHPNWhW3YbQR0C8WDQIUZlBR46TAqDPEizIAYetMWyQHexzIPRQVCQWc+e59NhY5ugBn1P3x8vvvDj8/0aYuvybGPbow+ATN887Ii0Woc762vQEDDf4cQsCvn8gvzdVy8EKyrpT0vjZ0mS1rJ3DrH75s/SS0h6RlqVcjPXAqHbhQpaXdLjM7ExSdJMeiTZ44nOljHHsPLeFqNN0vuzAE3jzU0/SnjXv6wJjsOiUoQffpwdJjNXf9SRPDDRZdJ5cBps8sTje2ccGqwnubeAijsTkqYutyakNAAhy1YxfFFCOV5V/zq4C2j/Iume97vQcxaqqML4yw+2JC2SlI8V9tQkFjxXbur4/a+tBFjeDAR4OO97uhm+IQpSvGFd9qNVbSjnyDFXSJNGr7sUPP2r1oo3eF0KfpA+Z9QfuPSiOt1PxJUMAYmBE/cbh1LffAeaw/u84L77xEhPadnS6H46htam+693R+tM0wyFjFuOypOwnkpO+dvazQA4XydXow9ilRsCIDuWnVuxgcjJK6dqDmzrhP4X/wIoZyGCBryiqgAAAABJRU5ErkJggg==",
      "text/plain": [
       "DistributionDraw(shape: torch.Size([28, 28]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds._get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor to have cpu Device, but got tensor with cuda:0 Device (while checking arguments for torch.take_along_dim():)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m features, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloader))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# features = features.to(\"cpu\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# features /= features.sum(dim=1, keepdim=True)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_along_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# features.sum(dim=1).shape\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor to have cpu Device, but got tensor with cuda:0 Device (while checking arguments for torch.take_along_dim():)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataloader = DataLoader(ds, batch_size=2 ** 18, shuffle=False)\n",
    "\n",
    "features, labels = next(iter(dataloader))\n",
    "\n",
    "# features = features.to(\"cpu\")\n",
    "\n",
    "# features /= features.sum(dim=1, keepdim=True)\n",
    "\n",
    "torch.take_along_dim(features, data, 1)\n",
    "\n",
    "# features.sum(dim=1).shape\n",
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosteriorSampler(n_data=1, n_models=161666, n_support=161666)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bwb.utils import _ArrayLike\n",
    "import torch\n",
    "from bwb.config import config\n",
    "import bwb.distributions as dist\n",
    "\n",
    "\n",
    "def _set_generator(seed=None, device=\"cpu\") -> torch.Generator:\n",
    "    gen = torch.Generator(device=device)\n",
    "    if seed is None:\n",
    "        gen.seed()\n",
    "        return gen\n",
    "    gen.manual_seed(seed)\n",
    "    return gen\n",
    "\n",
    "\n",
    "\n",
    "class ExplicitPosteriorSampler(DiscreteDistributionSampler[dist.DistributionDraw]):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._fitted = False\n",
    "        self.total_time = 0.0\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            data: _ArrayLike,\n",
    "            models: DiscreteModelsSet[dist.DistributionDraw],\n",
    "            batch_size: int = 256,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Fit the posterior distribution.\n",
    "\n",
    "        :param data: The data to fit the posterior.\n",
    "        :param models: The models to fit the posterior.\n",
    "        :param batch_size: The batch size to compute the probabilities.\n",
    "        :return: The fitted posterior.\n",
    "        \"\"\"\n",
    "        assert isinstance(models, DiscreteModelsSet), \"The models must be a DiscreteModelsSet.\"\n",
    "\n",
    "\n",
    "        self.data_: torch.Tensor = torch.as_tensor(data, device=config.device)\n",
    "        self.models_: DiscreteModelsSet[dist.DistributionDraw] = models\n",
    "        self.models_index_: torch.Tensor = torch.arange(len(models), device=config.device)\n",
    "\n",
    "        data = self.data_.reshape(1, -1)\n",
    "\n",
    "        self.probabilities_: torch.Tensor = models._compute_probability(data, batch_size=batch_size)\n",
    "\n",
    "        self.support_ = self.models_index_[self.probabilities_ > 0]\n",
    "\n",
    "        \n",
    "        self._fitted = True\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def get_model(self, i: int) -> dist.DistributionDraw:\n",
    "        \"\"\"Get the model with index i.\"\"\"\n",
    "        if self._models.get(i) is None:\n",
    "            self._models[i] = self.models_._get(i)\n",
    "        return self._models[i]\n",
    "\n",
    "    def _draw(self, seed=None, *args, **kwargs) -> tuple[_DistributionT, int]:\n",
    "        rng: torch.Generator = _set_generator(seed=seed, device=config.device)\n",
    "\n",
    "        i = torch.multinomial(input=self.probabilities_, num_samples=1, generator=rng).item()\n",
    "        i = int(i)\n",
    "        return self.get_model(i), i\n",
    "\n",
    "    def _rvs(self, size=1, seed=None, *args, **kwargs) -> tuple[t.Sequence[_DistributionT], list[int]]:\n",
    "        rng: torch.Generator = _set_generator(seed=seed, device=config.device)\n",
    "\n",
    "        indices = torch.multinomial(input=self.probabilities_, num_samples=size, replacement=True, generator=rng)\n",
    "        indices = indices.tolist()\n",
    "        return [self.get_model(i) for i in indices], indices\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        to_return = self.__class__.__name__\n",
    "\n",
    "        if not self._fitted:\n",
    "            to_return += \"()\"\n",
    "            return to_return\n",
    "\n",
    "        to_return += \"(\"\n",
    "        to_return += f\"n_data={len(self.data_)}, \"\n",
    "        to_return += f\"n_models={len(self.models_)}, \"\n",
    "        to_return += f\"n_support={len(self.support_)}\"\n",
    "        to_return += \")\"\n",
    "\n",
    "        return to_return\n",
    "        \n",
    "\n",
    "\n",
    "posterior = ExplicitPosteriorSampler(save_samples=True)\n",
    "\n",
    "posterior.fit(data, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB0ElEQVR4nH3TTUhUURjG8Wc+cJocGUZTKWoIKrHpw2UR5CIQaRFUgrSRoMS0IiOYSKbCTZtQAosoIawgF0HlKih3VqM1iJBmtkikFn06l6H0ZqP336J778yA9azOy4/Dec95OR707/gLqolh04zty9UAZN4B2Tu7JEm1o9j5i4c3AwcV3n7t89LtNd7ufJwrOQns9dRUq+ys+bNJF/PwoZLA4gw8b/LtNqzTOrHkYq++OscwEKwx6VC8AAdTtj5RD7QE0zk8YkSPOnvrV88zrrsOdvp1TL0At8ZgWD0sqMvBPTsr6jQJfFQzUL8VijptXFh57ktDpQVkGieATyNQGrcxqceT/gsUZF0b4Jc0rdj+ilOFb+5BklfSrMoIzS8zFa+kdFHoerpLkvq6h6x8BdojVvMVE7Jj5dIjwPpFtNVuqF/9jRtaIyukYPvQb6BtG5EzdkOHbsSnQgNhX3hj7SpJGrmZmDPWOsMe9SbybvEjVmW+1X132C2Bl67N7gg8Y1BJF43qyhnbxquKn0KfPrjI+/It3wG4Vxx9BVzyZXPIi9D6FBjHVfcNoKOEPOT1psDVy6X+84ssg2QOyNMwZReJcCFipd646+kHAJ7/fYc/tgnaDl7My3AAAAAASUVORK5CYII=",
      "text/plain": [
       "DistributionDraw(shape: torch.Size([28, 28]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{134021: DistributionDraw(shape: torch.Size([28, 28])),\n",
       " 35611: DistributionDraw(shape: torch.Size([28, 28]))}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior._models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
