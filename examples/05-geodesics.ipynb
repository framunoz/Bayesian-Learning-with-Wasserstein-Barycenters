{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Geodésicas\n",
    "Se buscará obtener las geodésicas y baricentros de la misma forma que en el ejemplo [Convolutional Wasserstein Barycenter](https://pythonot.github.io/auto_examples/barycenters/plot_convolutional_barycenter.html#sphx-glr-auto-examples-barycenters-plot-convolutional-barycenter-py), para luego obtener geodésicas implementadas en esta librería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/codeProjects/pythonProjects/Bayesian-Learning-with-Wasserstein-Barycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwb import config\n",
    "\n",
    "config.use_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ot\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# noinspection PyUnresolvedReferences\n",
    "from PIL.Image import Resampling\n",
    "\n",
    "# noinspection PyProtectedMember\n",
    "import bwb.bregman\n",
    "from bwb import logging\n",
    "from bwb import transports as tpt\n",
    "from bwb.distributions import *\n",
    "from bwb.geodesics import *\n",
    "\n",
    "_log = logging.get_logger(\"notebook\")\n",
    "# logging.set_level(logging.DEBUG)\n",
    "_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwb.config import config\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "main_path = Path(\".\")\n",
    "\n",
    "data_path = main_path / \"data\"\n",
    "data_images_path = data_path / \"images\"\n",
    "shapes_path = data_images_path / \"shapes\"\n",
    "pot_shapes_path = data_images_path / \"pot_shapes\"\n",
    "\n",
    "img_path = Path(\"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resolution = 128\n",
    "size = (resolution, resolution)\n",
    "resample = Resampling.LANCZOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # noinspection PyTypeChecker\n",
    "# f1 = 1 - np.asarray(Image.open(pot_shapes_path / 'redcross.png').resize(size, resample))[:, :, 2] / 255\n",
    "# # noinspection PyTypeChecker\n",
    "# f2 = 1 - np.asarray(Image.open(pot_shapes_path / 'tooth.png').resize(size, resample))[:, :, 2] / 255\n",
    "# # noinspection PyTypeChecker\n",
    "# f3 = 1 - np.asarray(Image.open(pot_shapes_path / 'heart.png').resize(size, resample))[:, :, 2] / 255\n",
    "# # noinspection PyTypeChecker\n",
    "# f4 = 1 - np.asarray(Image.open(pot_shapes_path / 'duck.png').resize(size, resample))[:, :, 2] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# noinspection PyTypeChecker\n",
    "f1 = (\n",
    "    1\n",
    "    - np.asarray(\n",
    "        Image.open(shapes_path / \"shape1filled.png\").resize(size, resample)\n",
    "    )[:, :, 2]\n",
    "    / 255\n",
    ")\n",
    "# noinspection PyTypeChecker\n",
    "f2 = (\n",
    "    1\n",
    "    - np.asarray(\n",
    "        Image.open(shapes_path / \"shape2filled.png\").resize(size, resample)\n",
    "    )[:, :, 2]\n",
    "    / 255\n",
    ")\n",
    "# noinspection PyTypeChecker\n",
    "f3 = (\n",
    "    1\n",
    "    - np.asarray(\n",
    "        Image.open(shapes_path / \"shape3filled.png\").resize(size, resample)\n",
    "    )[:, :, 2]\n",
    "    / 255\n",
    ")\n",
    "# noinspection PyTypeChecker\n",
    "f4 = (\n",
    "    1\n",
    "    - np.asarray(\n",
    "        Image.open(shapes_path / \"shape4filled.png\").resize(size, resample)\n",
    "    )[:, :, 2]\n",
    "    / 255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from bwb.config import config\n",
    "\n",
    "conf = config\n",
    "\n",
    "f1 = f1 / np.sum(f1)\n",
    "f2 = f2 / np.sum(f2)\n",
    "f3 = f3 / np.sum(f3)\n",
    "f4 = f4 / np.sum(f4)\n",
    "A = np.array([f1, f2, f3, f4])\n",
    "A = torch.tensor(A, dtype=conf.dtype, device=conf.device)\n",
    "\n",
    "nb_images = 5\n",
    "\n",
    "# those are the four corners coordinates that will be interpolated by bilinear\n",
    "# interpolation\n",
    "v1 = torch.tensor((1, 0, 0, 0), dtype=conf.dtype, device=conf.device)\n",
    "v2 = torch.tensor((0, 1, 0, 0), dtype=conf.dtype, device=conf.device)\n",
    "v3 = torch.tensor((0, 0, 1, 0), dtype=conf.dtype, device=conf.device)\n",
    "v4 = torch.tensor((0, 0, 0, 1), dtype=conf.dtype, device=conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "additional_info = f\"resol-{resolution}-nb-images-{nb_images}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "fig, axes = plt.subplots(nb_images, nb_images, figsize=(7, 7))\n",
    "cm = \"Blues\"\n",
    "# regularization parameter\n",
    "reg = 3e-3\n",
    "entrop_sharp = False\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(nb_images):\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "        ty = float(j) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        tmp1 = (1 - tx) * v1 + tx * v2\n",
    "        tmp2 = (1 - tx) * v3 + tx * v4\n",
    "        weights = (1 - ty) * tmp1 + ty * tmp2\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            axes[i, j].imshow(f1, cmap=cm)\n",
    "        elif i == 0 and j == (nb_images - 1):\n",
    "            axes[i, j].imshow(f3, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            axes[i, j].imshow(f2, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == (nb_images - 1):\n",
    "            axes[i, j].imshow(f4, cmap=cm)\n",
    "        else:\n",
    "            # call to barycenter computation\n",
    "            bar, log = bwb.bregman.convolutional_barycenter2d(\n",
    "                A,\n",
    "                reg,\n",
    "                weights,\n",
    "                entrop_sharp=entrop_sharp,\n",
    "                numItermax=1_000,\n",
    "                stopThr=1e-8,\n",
    "                # verbose=True,\n",
    "                warn=False,\n",
    "                log=True,\n",
    "            )\n",
    "            bar = bar.cpu()\n",
    "            axes[i, j].imshow(bar, cmap=cm)\n",
    "        axes[i, j].axis(\"off\")\n",
    "\n",
    "        toc = time.time()\n",
    "        _log.debug(f\"{i = }, {j = } ==> Total time: {toc - tic:.4f} [seg]\")\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nΔt={toc_-tic_:.1f}[seg]\"\n",
    "\n",
    "plt.suptitle(f\"Convolutional Wasserstein Barycenters in POT. {d_time}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(img_path / f\"{additional_info}-entrop-sharp-{entrop_sharp}-conv-wasserstein-bar.png\",\n",
    "#             dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "A_ = A[0:2]\n",
    "A_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.log(torch.tensor(config.eps))\n",
    "config.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "from bwb.config import config\n",
    "\n",
    "eps = config.eps\n",
    "\n",
    "nb_images = 7\n",
    "fig, axes = plt.subplots(1, nb_images, figsize=(7, 2))\n",
    "cm = \"Blues\"\n",
    "# regularization parameter\n",
    "reg = 4e-3\n",
    "entrop_sharp = False\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(1):\n",
    "        ax = axes[i]\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        weights = (1 - tx) * torch.tensor(\n",
    "            [1, 0], device=conf.device\n",
    "        ) + tx * torch.tensor([0, 1], device=conf.device)\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            ax.imshow(f1, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            ax.imshow(f2, cmap=cm)\n",
    "        else:\n",
    "            # call to barycenter computation\n",
    "            bar, log = bwb.bregman.convolutional_barycenter2d(\n",
    "                A_,\n",
    "                reg,\n",
    "                weights,\n",
    "                # entrop_sharp=entrop_sharp,\n",
    "                numItermax=1_000,\n",
    "                stopThr=1e-8,\n",
    "                # verbose=True,\n",
    "                warn=False,\n",
    "                log=True,\n",
    "            )\n",
    "            V, W = log[\"V\"], log[\"W\"]\n",
    "            dist_conv = reg * torch.sum(\n",
    "                A_[0] * torch.log(W[0] + eps) + bar * torch.log(V[0] + eps)\n",
    "            )\n",
    "            # dist_conv = reg * torch.sum(A_[0] * torch.log(V[0] + eps) + A_[1] * torch.log(W[0] + eps))\n",
    "            print(f\"{dist_conv = :.6f}\")\n",
    "            bar = bar.cpu()\n",
    "            ax.imshow(bar, cmap=cm)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        toc = time.time()\n",
    "        _log.debug(f\"{i = }, {j = } ==> Total time: {toc - tic:.4f} [seg]\")\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nΔt={toc_-tic_:.1f}[seg]\"\n",
    "\n",
    "plt.suptitle(f\"Convolutional Wasserstein Barycenters in POT. {d_time}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(img_path / f\"{additional_info}-entrop-sharp-{entrop_sharp}-conv-wasserstein-bar.png\",\n",
    "#             dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "A_[0].type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# # Set these to whatever you want for your gaussian filter\n",
    "# kernel_size = 15\n",
    "# sigma = 1\n",
    "# channels = 1\n",
    "\n",
    "# # Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
    "# x_cord = torch.arange(kernel_size)\n",
    "# x_grid = x_cord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "# y_grid = x_grid.t()\n",
    "# xy_grid = torch.stack([x_grid, y_grid], dim=-1)\n",
    "\n",
    "# mean = (kernel_size - 1)/2.\n",
    "# variance = sigma**2.\n",
    "\n",
    "# # Calculate the 2-dimensional gaussian kernel which is\n",
    "# # the product of two gaussian distributions for two different\n",
    "# # variables (in this case called x and y)\n",
    "# gaussian_kernel = torch.exp(\n",
    "#     -torch.sum((xy_grid - mean)**2., dim=-1) / (2*variance)\n",
    "# )\n",
    "\n",
    "# # Make sure sum of values in gaussian kernel equals 1.\n",
    "# gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
    "\n",
    "# # Reshape to 2d depthwise convolutional weight\n",
    "# gaussian_kernel = gaussian_kernel.view(1, 1, kernel_size, kernel_size)\n",
    "# gaussian_kernel = gaussian_kernel.repeat(channels, 1, 1, 1)\n",
    "\n",
    "# gaussian_filter = nn.Conv2d(in_channels=channels, out_channels=channels,\n",
    "#                             kernel_size=kernel_size, groups=channels, bias=False,\n",
    "#                             padding=kernel_size//2)\n",
    "\n",
    "# gaussian_filter.weight.data = gaussian_kernel\n",
    "# gaussian_filter.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# gaussian_kernel, gaussian_kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# img = A_[0].unsqueeze(0).unsqueeze(0)\n",
    "# img: torch.Tensor = gaussian_filter(img.type(torch.float))\n",
    "# img = img.squeeze()\n",
    "# img = 255 * img / img.max()\n",
    "# img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from bwb.distributions.discrete_distribution import DistributionDraw\n",
    "\n",
    "# DistributionDraw.from_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "sigma = 0.01\n",
    "kernel_size = math.ceil(6 * sigma + 1)\n",
    "kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = A\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigma = 10\n",
    "kernel_size = min(math.ceil(6 * sigma + 1), 127 * 2)\n",
    "if kernel_size % 2 == 0:\n",
    "    kernel_size += 1\n",
    "print(f\"{kernel_size = }, {sigma = }\")\n",
    "# blurrer = torchvision.transforms.GaussianBlur(129, sigma=sigma)\n",
    "blurrer = torchvision.transforms.GaussianBlur(\n",
    "    kernel_size=kernel_size, sigma=sigma\n",
    ")\n",
    "\n",
    "# img = A_[0].unsqueeze(0).unsqueeze(0)\n",
    "img = A\n",
    "img_ = blurrer(img)\n",
    "# img = img.squeeze()\n",
    "# print(f\"{img.sum() = }\")\n",
    "img = img_[0]\n",
    "print(img.sum())\n",
    "img = 255 * img / img.max()\n",
    "print(f\"{img.size() = }\")\n",
    "DistributionDraw.from_array(img)\n",
    "\n",
    "img = img_[1]\n",
    "img = 255 * img / img.max()\n",
    "print(f\"{img.size() = }\")\n",
    "DistributionDraw.from_array(img)\n",
    "\n",
    "img = img_[2]\n",
    "img = 255 * img / img.max()\n",
    "print(f\"{img.size() = }\")\n",
    "DistributionDraw.from_array(img)\n",
    "\n",
    "img = img_[3]\n",
    "img = 255 * img / img.max()\n",
    "print(f\"{img.size() = }\")\n",
    "DistributionDraw.from_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ot.backend import get_backend\n",
    "\n",
    "reg = 3e-4\n",
    "\n",
    "nx = get_backend(A)\n",
    "\n",
    "dtype, device = nx.dtype_device(A)\n",
    "\n",
    "# this is equivalent to blurring on horizontal then vertical directions\n",
    "t = nx.linspace(0, 1, A.shape[1]).to(dtype=dtype, device=device)\n",
    "[Y, X] = nx.meshgrid(t, t)\n",
    "K1 = nx.exp(-((X - Y) ** 2) / reg)\n",
    "\n",
    "t = nx.linspace(0, 1, A.shape[2]).to(dtype=dtype, device=device)\n",
    "[Y, X] = nx.meshgrid(t, t)\n",
    "K2 = nx.exp(-((X - Y) ** 2) / reg)\n",
    "\n",
    "\n",
    "def convol_imgs(imgs):\n",
    "    kx = nx.einsum(\"...ij,kjl->kil\", K1, imgs)\n",
    "    kxy = nx.einsum(\"...ij,klj->kli\", K2, kx)\n",
    "    return kxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = A\n",
    "img_ = convol_imgs(img)\n",
    "# img = img.squeeze()\n",
    "# print(f\"{img.sum() = }\")\n",
    "img = img_[0]\n",
    "print(img.sum())\n",
    "img = 255 * img / img.max()\n",
    "print(f\"{img.size() = }\")\n",
    "DistributionDraw.from_array(img)\n",
    "\n",
    "# img = img_[1]\n",
    "# img = 255 * img / img.max()\n",
    "# print(f\"{img.size() = }\")\n",
    "# DistributionDraw.from_array(img)\n",
    "\n",
    "# img = img_[2]\n",
    "# img = 255 * img / img.max()\n",
    "# print(f\"{img.size() = }\")\n",
    "# DistributionDraw.from_array(img)\n",
    "\n",
    "# img = img_[3]\n",
    "# img = 255 * img / img.max()\n",
    "# print(f\"{img.size() = }\")\n",
    "# DistributionDraw.from_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Utilizando geodésicas\n",
    "Ahora que tenemos los resultados replicados del notebook de ejemplo, se procederá a replicar los resultados utilizando las clases creadas en esta librería, sólo calculando las geodésicas de par a par."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "original_shape = f1.shape\n",
    "\n",
    "dd1 = DistributionDraw.from_weights(f1.reshape(-1), original_shape)\n",
    "dd2 = DistributionDraw.from_weights(f2.reshape(-1), original_shape)\n",
    "dd3 = DistributionDraw.from_weights(f3.reshape(-1), original_shape)\n",
    "dd4 = DistributionDraw.from_weights(f4.reshape(-1), original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weights = \n",
    "bwb.bregman.convolutional_barycenter2d(A, reg, weights,\n",
    "                                       entrop_sharp=entrop_sharp, \n",
    "                                       numItermax=1_000,\n",
    "                                       stopThr=1e-8,\n",
    "#                                        verbose=True,\n",
    "                                       warn=False),"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ahora se realizarán las matrices que serán graficadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "geodesic12 = McCannGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(\n",
    "    dd_s=dd1, dd_t=dd2\n",
    ")\n",
    "geodesic13 = McCannGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(\n",
    "    dd_s=dd1, dd_t=dd3\n",
    ")\n",
    "geodesic34 = McCannGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(\n",
    "    dd_s=dd3, dd_t=dd4\n",
    ")\n",
    "geodesic24 = McCannGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(\n",
    "    dd_s=dd2, dd_t=dd4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "fig, axes = plt.subplots(nb_images, nb_images, figsize=(7, 7))\n",
    "cm = \"Blues\"\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(nb_images):\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "        ty = float(j) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        tmp1 = (1 - tx) * v1 + tx * v2\n",
    "        tmp2 = (1 - tx) * v3 + tx * v4\n",
    "        weights = (1 - ty) * tmp1 + ty * tmp2\n",
    "\n",
    "        axes_ij = axes[i, j]\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            axes_ij.imshow(f1, cmap=cm)\n",
    "        elif i == 0 and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f3, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            axes_ij.imshow(f2, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f4, cmap=cm)\n",
    "        elif i == 0:\n",
    "            dd_t = DistributionDraw(*geodesic13.interpolate(ty), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif i == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic24.interpolate(ty), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == 0:\n",
    "            dd_t = DistributionDraw(*geodesic12.interpolate(tx), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic34.interpolate(tx), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        else:\n",
    "            axes_ij.imshow(np.zeros(original_shape), cmap=cm)\n",
    "        axes_ij.axis(\"off\")\n",
    "\n",
    "        toc = time.time()\n",
    "        _log.debug(f\"{i = }, {j = } ==> Total time: {toc - tic:.4f} [seg]\")\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nΔt={toc_-tic_:.1f}[seg]\"\n",
    "\n",
    "plt.suptitle(f\"McCann Interpolation with EMD Transport. {d_time}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path / f\"{additional_info}-mccaan-interpolation-emd.png\", dpi=800\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Interpolación con la proyección baricéntrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "geodesic12 = BarycentricProjGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(\n",
    "    dd_s=dd1, dd_t=dd2\n",
    ")\n",
    "geodesic13 = BarycentricProjGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(\n",
    "    dd_s=dd1, dd_t=dd3\n",
    ")\n",
    "geodesic34 = BarycentricProjGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(\n",
    "    dd_s=dd3, dd_t=dd4\n",
    ")\n",
    "geodesic24 = BarycentricProjGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(\n",
    "    dd_s=dd2, dd_t=dd4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "fig, axes = plt.subplots(nb_images, nb_images, figsize=(7, 7))\n",
    "cm = \"Blues\"\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(nb_images):\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "        ty = float(j) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        tmp1 = (1 - tx) * v1 + tx * v2\n",
    "        tmp2 = (1 - tx) * v3 + tx * v4\n",
    "        weights = (1 - ty) * tmp1 + ty * tmp2\n",
    "\n",
    "        axes_ij = axes[i, j]\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            axes_ij.imshow(f1, cmap=cm)\n",
    "        elif i == 0 and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f3, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            axes_ij.imshow(f2, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f4, cmap=cm)\n",
    "        elif i == 0:\n",
    "            dd_t = DistributionDraw(*geodesic13.interpolate(ty), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif i == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic24.interpolate(ty), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == 0:\n",
    "            dd_t = DistributionDraw(*geodesic12.interpolate(tx), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic34.interpolate(tx), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        else:\n",
    "            axes_ij.imshow(np.zeros(original_shape), cmap=cm)\n",
    "        axes_ij.axis(\"off\")\n",
    "\n",
    "        toc = time.time()\n",
    "        _log.debug(f\"{i = }, {j = } ==> Total time: {toc - tic:.4f} [seg]\")\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nΔt={toc_-tic_:.1f}[seg]\"\n",
    "plt.suptitle(\n",
    "    f\"Barycentric Projection Interpolation with EMD Transport. {d_time}\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path / f\"{additional_info}-barycentric-proj-interpolation-emd.png\",\n",
    "    dpi=800,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Interpolación con la proyección baricéntrica particionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "geodesic12 = PartitionedBarycentricProjGeodesic(\n",
    "    tpt.EMDTransport(max_iter=250_000), alpha=0.1\n",
    ").fit_wd(dd_s=dd1, dd_t=dd2)\n",
    "geodesic13 = PartitionedBarycentricProjGeodesic(\n",
    "    tpt.EMDTransport(max_iter=250_000), alpha=0.1\n",
    ").fit_wd(dd_s=dd1, dd_t=dd3)\n",
    "geodesic34 = PartitionedBarycentricProjGeodesic(\n",
    "    tpt.EMDTransport(max_iter=250_000), alpha=0.1\n",
    ").fit_wd(dd_s=dd3, dd_t=dd4)\n",
    "geodesic24 = PartitionedBarycentricProjGeodesic(\n",
    "    tpt.EMDTransport(max_iter=250_000), alpha=0.1\n",
    ").fit_wd(dd_s=dd2, dd_t=dd4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "fig, axes = plt.subplots(nb_images, nb_images, figsize=(7, 7))\n",
    "cm = \"Blues\"\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(nb_images):\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "        ty = float(j) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        tmp1 = (1 - tx) * v1 + tx * v2\n",
    "        tmp2 = (1 - tx) * v3 + tx * v4\n",
    "        weights = (1 - ty) * tmp1 + ty * tmp2\n",
    "\n",
    "        axes_ij = axes[i, j]\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            axes_ij.imshow(f1, cmap=cm)\n",
    "        elif i == 0 and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f3, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            axes_ij.imshow(f2, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f4, cmap=cm)\n",
    "        elif i == 0:\n",
    "            dd_t = DistributionDraw(*geodesic13.interpolate(ty), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif i == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic24.interpolate(ty), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == 0:\n",
    "            dd_t = DistributionDraw(*geodesic12.interpolate(tx), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic34.interpolate(tx), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        else:\n",
    "            axes_ij.imshow(np.zeros(original_shape), cmap=cm)\n",
    "        axes_ij.axis(\"off\")\n",
    "\n",
    "        toc = time.time()\n",
    "        _log.debug(f\"{i = }, {j = } ==> Total time: {toc - tic:.4f} [seg]\")\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nΔt={toc_-tic_:.1f}[seg]\"\n",
    "plt.suptitle(\n",
    "    \"Partitioned Barycentric Projection Interpolation with EMD Transport.\"\n",
    "    f\" {d_time}\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path / f\"{additional_info}-barycentric-proj-interpolation-emd.png\",\n",
    "    dpi=800,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Interpolación con Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kwargs = {\"max_iter\": 250_000, \"reg_e\": 1e-3, \"norm\": \"max\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "geodesic12 = McCannGeodesic(tpt.SinkhornTransport(**kwargs)).fit_wd(\n",
    "    dd_s=dd1, dd_t=dd2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "interp_param = {}\n",
    "# interp_param = {\n",
    "#     \"rtol\": ,\n",
    "#     \"atol\": 0,\n",
    "# }\n",
    "\n",
    "DistributionDraw(*geodesic12.interpolate(0.5, **interp_param), original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "geodesic13 = McCannGeodesic(tpt.SinkhornTransport(**kwargs)).fit_wd(\n",
    "    dd_s=dd1, dd_t=dd3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "geodesic34 = McCannGeodesic(tpt.SinkhornTransport(**kwargs)).fit_wd(\n",
    "    dd_s=dd3, dd_t=dd4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "geodesic24 = McCannGeodesic(tpt.SinkhornTransport(**kwargs)).fit_wd(\n",
    "    dd_s=dd2, dd_t=dd4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nb_images, nb_images, figsize=(7, 7))\n",
    "cm = \"Blues\"\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(nb_images):\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "        ty = float(j) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        tmp1 = (1 - tx) * v1 + tx * v2\n",
    "        tmp2 = (1 - tx) * v3 + tx * v4\n",
    "        weights = (1 - ty) * tmp1 + ty * tmp2\n",
    "\n",
    "        axes_ij = axes[i, j]\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            axes_ij.imshow(f1, cmap=cm)\n",
    "        elif i == 0 and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f3, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            axes_ij.imshow(f2, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f4, cmap=cm)\n",
    "        elif i == 0:\n",
    "            dd_t = DistributionDraw(\n",
    "                *geodesic13.interpolate(ty, **interp_param), original_shape\n",
    "            )\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif i == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(\n",
    "                *geodesic24.interpolate(ty, **interp_param), original_shape\n",
    "            )\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == 0:\n",
    "            dd_t = DistributionDraw(\n",
    "                *geodesic12.interpolate(tx, **interp_param), original_shape\n",
    "            )\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(\n",
    "                *geodesic34.interpolate(tx, **interp_param), original_shape\n",
    "            )\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        else:\n",
    "            axes_ij.imshow(np.zeros(original_shape), cmap=cm)\n",
    "        axes_ij.axis(\"off\")\n",
    "\n",
    "        toc = time.time()\n",
    "        _log.debug(f\"{i = }, {j = } ==> Total time: {toc - tic:.4f} [seg]\")\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nΔt={toc_-tic_:.1f}[seg]\"\n",
    "plt.suptitle(f\"McCann Interpolation with Sinkhorn Transport. {d_time}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path / f\"{additional_info}-mccaan-interpolation-sinkhorn.png\", dpi=800\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
