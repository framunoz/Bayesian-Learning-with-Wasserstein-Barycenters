{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Geodésicas\n",
    "Se buscará obtener las geodésicas y baricentros de la misma forma que en el ejemplo [Convolutional Wasserstein Barycenter](https://pythonot.github.io/auto_examples/barycenters/plot_convolutional_barycenter.html#sphx-glr-auto-examples-barycenters-plot-convolutional-barycenter-py), para luego obtener geodésicas implementadas en esta librería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "%cd ~/codeProjects/pythonProjects/Bayesian-Learning-with-Wasserstein-Barycenters"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "from bwb import config\n",
    "\n",
    "config.use_cpu()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ot\n",
    "import torch\n",
    "from PIL import Image\n",
    "# noinspection PyUnresolvedReferences\n",
    "from PIL.Image import Resampling\n",
    "\n",
    "# noinspection PyProtectedMember\n",
    "import bwb.bregman\n",
    "from bwb import logging\n",
    "from bwb import transports as tpt\n",
    "from bwb.distributions import *\n",
    "from bwb.geodesics import *\n",
    "\n",
    "_log = logging.get_logger(\"notebook\")\n",
    "# logging.set_level(logging.DEBUG)\n",
    "_log"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "from bwb.config import config\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "main_path = Path(\".\")\n",
    "\n",
    "data_path = main_path / \"data\"\n",
    "data_images_path = data_path / \"images\"\n",
    "shapes_path = data_images_path / \"shapes\"\n",
    "pot_shapes_path = data_images_path / \"pot_shapes\"\n",
    "\n",
    "img_path = Path(\"img\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "resolution = 128\n",
    "size = (resolution, resolution)\n",
    "resample = Resampling.LANCZOS"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# # noinspection PyTypeChecker\n",
    "# f1 = 1 - np.asarray(Image.open(pot_shapes_path / 'redcross.png').resize(size, resample))[:, :, 2] / 255\n",
    "# # noinspection PyTypeChecker\n",
    "# f2 = 1 - np.asarray(Image.open(pot_shapes_path / 'tooth.png').resize(size, resample))[:, :, 2] / 255\n",
    "# # noinspection PyTypeChecker\n",
    "# f3 = 1 - np.asarray(Image.open(pot_shapes_path / 'heart.png').resize(size, resample))[:, :, 2] / 255\n",
    "# # noinspection PyTypeChecker\n",
    "# f4 = 1 - np.asarray(Image.open(pot_shapes_path / 'duck.png').resize(size, resample))[:, :, 2] / 255"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# noinspection PyTypeChecker\n",
    "f1 = 1 - np.asarray(Image.open(shapes_path / 'shape1filled.png').resize(size, resample))[:, :, 2] / 255\n",
    "# noinspection PyTypeChecker\n",
    "f2 = 1 - np.asarray(Image.open(shapes_path / 'shape2filled.png').resize(size, resample))[:, :, 2] / 255\n",
    "# noinspection PyTypeChecker\n",
    "f3 = 1 - np.asarray(Image.open(shapes_path / 'shape3filled.png').resize(size, resample))[:, :, 2] / 255\n",
    "# noinspection PyTypeChecker\n",
    "f4 = 1 - np.asarray(Image.open(shapes_path / 'shape4filled.png').resize(size, resample))[:, :, 2] / 255"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from bwb.config import config\n",
    "conf = config\n",
    "\n",
    "f1 = f1 / np.sum(f1)\n",
    "f2 = f2 / np.sum(f2)\n",
    "f3 = f3 / np.sum(f3)\n",
    "f4 = f4 / np.sum(f4)\n",
    "A = np.array([f1, f2, f3, f4])\n",
    "A = torch.tensor(A, dtype=conf.dtype, device=conf.device)\n",
    "\n",
    "nb_images = 5\n",
    "\n",
    "# those are the four corners coordinates that will be interpolated by bilinear\n",
    "# interpolation\n",
    "v1 = torch.tensor((1, 0, 0, 0), dtype=conf.dtype, device=conf.device)\n",
    "v2 = torch.tensor((0, 1, 0, 0), dtype=conf.dtype, device=conf.device)\n",
    "v3 = torch.tensor((0, 0, 1, 0), dtype=conf.dtype, device=conf.device)\n",
    "v4 = torch.tensor((0, 0, 0, 1), dtype=conf.dtype, device=conf.device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "additional_info = f\"resol-{resolution}-nb-images-{nb_images}\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "fig, axes = plt.subplots(nb_images, nb_images, figsize=(7, 7))\n",
    "cm = 'Blues'\n",
    "# regularization parameter\n",
    "reg = 3e-3\n",
    "entrop_sharp = False\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(nb_images):\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "        ty = float(j) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        tmp1 = (1 - tx) * v1 + tx * v2\n",
    "        tmp2 = (1 - tx) * v3 + tx * v4\n",
    "        weights = (1 - ty) * tmp1 + ty * tmp2\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            axes[i, j].imshow(f1, cmap=cm)\n",
    "        elif i == 0 and j == (nb_images - 1):\n",
    "            axes[i, j].imshow(f3, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            axes[i, j].imshow(f2, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == (nb_images - 1):\n",
    "            axes[i, j].imshow(f4, cmap=cm)\n",
    "        else:\n",
    "            # call to barycenter computation\n",
    "            bar, log = bwb.bregman.convolutional_barycenter2d(\n",
    "                A, reg, weights,\n",
    "                entrop_sharp=entrop_sharp,\n",
    "                numItermax=1_000, stopThr=1e-8,\n",
    "                # verbose=True,\n",
    "                warn=False,\n",
    "                log=True,\n",
    "            )\n",
    "            bar = bar.cpu()\n",
    "            axes[i, j].imshow(bar, cmap=cm)\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "        toc = time.time()\n",
    "        _log.debug(f\"{i = }, {j = } ==> Total time: {toc - tic:.4f} [seg]\")\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nΔt={toc_-tic_:.1f}[seg]\"\n",
    "\n",
    "plt.suptitle(f'Convolutional Wasserstein Barycenters in POT. {d_time}')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(img_path / f\"{additional_info}-entrop-sharp-{entrop_sharp}-conv-wasserstein-bar.png\",\n",
    "#             dpi=400)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "A_ = A[0:2]\n",
    "A_.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "torch.log(\n",
    "    torch.tensor(config.eps)\n",
    ")\n",
    "config.eps"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%time\n",
    "import time\n",
    "from bwb.config import config\n",
    "eps = config.eps\n",
    "\n",
    "nb_images = 7\n",
    "fig, axes = plt.subplots(1, nb_images, figsize=(7, 2))\n",
    "cm = 'Blues'\n",
    "# regularization parameter\n",
    "reg = 4e-3\n",
    "entrop_sharp = False\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(1):\n",
    "        ax = axes[i]\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        weights = (1 - tx) * torch.tensor([1, 0], device=conf.device) + tx * torch.tensor([0, 1], device=conf.device)\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            ax.imshow(f1, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            ax.imshow(f2, cmap=cm)\n",
    "        else:\n",
    "            # call to barycenter computation\n",
    "            bar, log = bwb.bregman.convolutional_barycenter2d(\n",
    "                A_, reg, weights,\n",
    "                # entrop_sharp=entrop_sharp,\n",
    "                numItermax=1_000, stopThr=1e-8,\n",
    "                # verbose=True,\n",
    "                warn=False,\n",
    "                log=True,\n",
    "            )\n",
    "            V, W = log[\"V\"], log[\"W\"]\n",
    "            dist_conv = reg * torch.sum(A_[0] * torch.log(W[0] + eps)\n",
    "                                        + bar * torch.log(V[0] + eps))\n",
    "            # dist_conv = reg * torch.sum(A_[0] * torch.log(V[0] + eps) + A_[1] * torch.log(W[0] + eps))\n",
    "            print(f\"{dist_conv = :.6f}\")\n",
    "            bar = bar.cpu()\n",
    "            ax.imshow(bar, cmap=cm)\n",
    "        ax.axis('off')\n",
    "\n",
    "        toc = time.time()\n",
    "        _log.debug(f\"{i = }, {j = } ==> Total time: {toc - tic:.4f} [seg]\")\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nΔt={toc_-tic_:.1f}[seg]\"\n",
    "\n",
    "plt.suptitle(f'Convolutional Wasserstein Barycenters in POT. {d_time}')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(img_path / f\"{additional_info}-entrop-sharp-{entrop_sharp}-conv-wasserstein-bar.png\",\n",
    "#             dpi=400)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "log"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "A_[0].type(torch.float)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# # Set these to whatever you want for your gaussian filter\n",
    "# kernel_size = 15\n",
    "# sigma = 1\n",
    "# channels = 1\n",
    "\n",
    "# # Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
    "# x_cord = torch.arange(kernel_size)\n",
    "# x_grid = x_cord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "# y_grid = x_grid.t()\n",
    "# xy_grid = torch.stack([x_grid, y_grid], dim=-1)\n",
    "\n",
    "# mean = (kernel_size - 1)/2.\n",
    "# variance = sigma**2.\n",
    "\n",
    "# # Calculate the 2-dimensional gaussian kernel which is\n",
    "# # the product of two gaussian distributions for two different\n",
    "# # variables (in this case called x and y)\n",
    "# gaussian_kernel = torch.exp(\n",
    "#     -torch.sum((xy_grid - mean)**2., dim=-1) / (2*variance)\n",
    "# )\n",
    "\n",
    "# # Make sure sum of values in gaussian kernel equals 1.\n",
    "# gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
    "\n",
    "# # Reshape to 2d depthwise convolutional weight\n",
    "# gaussian_kernel = gaussian_kernel.view(1, 1, kernel_size, kernel_size)\n",
    "# gaussian_kernel = gaussian_kernel.repeat(channels, 1, 1, 1)\n",
    "\n",
    "# gaussian_filter = nn.Conv2d(in_channels=channels, out_channels=channels,\n",
    "#                             kernel_size=kernel_size, groups=channels, bias=False,\n",
    "#                             padding=kernel_size//2)\n",
    "\n",
    "# gaussian_filter.weight.data = gaussian_kernel\n",
    "# gaussian_filter.weight.requires_grad = False"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# gaussian_kernel, gaussian_kernel.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# img = A_[0].unsqueeze(0).unsqueeze(0)\n",
    "# img: torch.Tensor = gaussian_filter(img.type(torch.float))\n",
    "# img = img.squeeze()\n",
    "# img = 255 * img / img.max()\n",
    "# img.size()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from bwb.distributions.discrete_distribution import DistributionDraw\n",
    "# DistributionDraw.from_array(img)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "import math\n",
    "\n",
    "sigma = 0.01\n",
    "kernel_size = math.ceil(6 * sigma + 1)\n",
    "kernel_size"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "img = A\n",
    "img.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "sigma = 10\n",
    "kernel_size = min(math.ceil(6 * sigma + 1), 127*2)\n",
    "if kernel_size % 2 == 0:\n",
    "    kernel_size += 1\n",
    "print(f\"{kernel_size = }, {sigma = }\")\n",
    "# blurrer = torchvision.transforms.GaussianBlur(129, sigma=sigma)\n",
    "blurrer = torchvision.transforms.GaussianBlur(kernel_size=kernel_size, sigma=sigma)\n",
    "\n",
    "# img = A_[0].unsqueeze(0).unsqueeze(0)\n",
    "img = A\n",
    "img_ = blurrer(img)\n",
    "# img = img.squeeze()\n",
    "# print(f\"{img.sum() = }\")\n",
    "img = img_[0]\n",
    "print(img.sum())\n",
    "img = 255 * img / img.max()\n",
    "print(f\"{img.size() = }\")\n",
    "DistributionDraw.from_array(img)\n",
    "\n",
    "img = img_[1]\n",
    "img = 255 * img / img.max()\n",
    "print(f\"{img.size() = }\")\n",
    "DistributionDraw.from_array(img)\n",
    "\n",
    "img = img_[2]\n",
    "img = 255 * img / img.max()\n",
    "print(f\"{img.size() = }\")\n",
    "DistributionDraw.from_array(img)\n",
    "\n",
    "img = img_[3]\n",
    "img = 255 * img / img.max()\n",
    "print(f\"{img.size() = }\")\n",
    "DistributionDraw.from_array(img)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "\n",
    "from ot.backend import get_backend\n",
    "\n",
    "reg = 3e-4\n",
    "\n",
    "nx = get_backend(A)\n",
    "\n",
    "dtype, device = nx.dtype_device(A)\n",
    "    \n",
    "# this is equivalent to blurring on horizontal then vertical directions\n",
    "t = nx.linspace(0, 1, A.shape[1]).to(dtype=dtype, device=device)\n",
    "[Y, X] = nx.meshgrid(t, t)\n",
    "K1 = nx.exp(-(X - Y) ** 2 / reg)\n",
    "\n",
    "t = nx.linspace(0, 1, A.shape[2]).to(dtype=dtype, device=device)\n",
    "[Y, X] = nx.meshgrid(t, t)\n",
    "K2 = nx.exp(-(X - Y) ** 2 / reg)\n",
    "\n",
    "def convol_imgs(imgs):\n",
    "    kx = nx.einsum(\"...ij,kjl->kil\", K1, imgs)\n",
    "    kxy = nx.einsum(\"...ij,klj->kli\", K2, kx)\n",
    "    return kxy"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "A[0].sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "source": [
    "\n",
    "img = A\n",
    "img_ = convol_imgs(img)\n",
    "# img = img.squeeze()\n",
    "# print(f\"{img.sum() = }\")\n",
    "img = img_[0]\n",
    "print(img.sum())\n",
    "img = 255 * img / img.max()\n",
    "print(f\"{img.size() = }\")\n",
    "DistributionDraw.from_array(img)\n",
    "\n",
    "# img = img_[1]\n",
    "# img = 255 * img / img.max()\n",
    "# print(f\"{img.size() = }\")\n",
    "# DistributionDraw.from_array(img)\n",
    "\n",
    "# img = img_[2]\n",
    "# img = 255 * img / img.max()\n",
    "# print(f\"{img.size() = }\")\n",
    "# DistributionDraw.from_array(img)\n",
    "\n",
    "# img = img_[3]\n",
    "# img = 255 * img / img.max()\n",
    "# print(f\"{img.size() = }\")\n",
    "# DistributionDraw.from_array(img)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "source": [
    "img"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "img_.shape"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Utilizando geodésicas\n",
    "Ahora que tenemos los resultados replicados del notebook de ejemplo, se procederá a replicar los resultados utilizando las clases creadas en esta librería, sólo calculando las geodésicas de par a par."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "original_shape = f1.shape\n",
    "\n",
    "dd1 = DistributionDraw.from_weights(f1.reshape(-1), original_shape)\n",
    "dd2 = DistributionDraw.from_weights(f2.reshape(-1), original_shape)\n",
    "dd3 = DistributionDraw.from_weights(f3.reshape(-1), original_shape)\n",
    "dd4 = DistributionDraw.from_weights(f4.reshape(-1), original_shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "weights = \n",
    "bwb.bregman.convolutional_barycenter2d(A, reg, weights,\n",
    "                                       entrop_sharp=entrop_sharp, \n",
    "                                       numItermax=1_000,\n",
    "                                       stopThr=1e-8,\n",
    "#                                        verbose=True,\n",
    "                                       warn=False),"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ahora se realizarán las matrices que serán graficadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%time\n",
    "geodesic12 = McCannGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(dd_s=dd1, dd_t=dd2)\n",
    "geodesic13 = McCannGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(dd_s=dd1, dd_t=dd3)\n",
    "geodesic34 = McCannGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(dd_s=dd3, dd_t=dd4)\n",
    "geodesic24 = McCannGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(dd_s=dd2, dd_t=dd4)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "fig, axes = plt.subplots(nb_images, nb_images, figsize=(7, 7))\n",
    "cm = 'Blues'\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(nb_images):\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "        ty = float(j) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        tmp1 = (1 - tx) * v1 + tx * v2\n",
    "        tmp2 = (1 - tx) * v3 + tx * v4\n",
    "        weights = (1 - ty) * tmp1 + ty * tmp2\n",
    "\n",
    "        axes_ij = axes[i, j]\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            axes_ij.imshow(f1, cmap=cm)\n",
    "        elif i == 0 and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f3, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            axes_ij.imshow(f2, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f4, cmap=cm)\n",
    "        elif i == 0:\n",
    "            dd_t = DistributionDraw(*geodesic13.interpolate(ty), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif i == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic24.interpolate(ty), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == 0:\n",
    "            dd_t = DistributionDraw(*geodesic12.interpolate(tx), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic34.interpolate(tx), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        else:\n",
    "            axes_ij.imshow(np.zeros(original_shape), cmap=cm)\n",
    "        axes_ij.axis('off')\n",
    "\n",
    "        toc = time.time()\n",
    "        _log.debug(f\"{i = }, {j = } ==> Total time: {toc - tic:.4f} [seg]\")\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nΔt={toc_-tic_:.1f}[seg]\"\n",
    "\n",
    "plt.suptitle(f'McCann Interpolation with EMD Transport. {d_time}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path / f\"{additional_info}-mccaan-interpolation-emd.png\", dpi=800)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Interpolación con la proyección baricéntrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%time\n",
    "geodesic12 = BarycentricProjGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(dd_s=dd1, dd_t=dd2)\n",
    "geodesic13 = BarycentricProjGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(dd_s=dd1, dd_t=dd3)\n",
    "geodesic34 = BarycentricProjGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(dd_s=dd3, dd_t=dd4)\n",
    "geodesic24 = BarycentricProjGeodesic(tpt.EMDTransport(max_iter=250_000)).fit_wd(dd_s=dd2, dd_t=dd4)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "fig, axes = plt.subplots(nb_images, nb_images, figsize=(7, 7))\n",
    "cm = 'Blues'\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(nb_images):\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "        ty = float(j) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        tmp1 = (1 - tx) * v1 + tx * v2\n",
    "        tmp2 = (1 - tx) * v3 + tx * v4\n",
    "        weights = (1 - ty) * tmp1 + ty * tmp2\n",
    "\n",
    "        axes_ij = axes[i, j]\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            axes_ij.imshow(f1, cmap=cm)\n",
    "        elif i == 0 and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f3, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            axes_ij.imshow(f2, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f4, cmap=cm)\n",
    "        elif i == 0:\n",
    "            dd_t = DistributionDraw(*geodesic13.interpolate(ty), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif i == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic24.interpolate(ty), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == 0:\n",
    "            dd_t = DistributionDraw(*geodesic12.interpolate(tx), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic34.interpolate(tx), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        else:\n",
    "            axes_ij.imshow(np.zeros(original_shape), cmap=cm)\n",
    "        axes_ij.axis('off')\n",
    "\n",
    "        toc = time.time()\n",
    "        _log.debug(f\"{i = }, {j = } ==> Total time: {toc - tic:.4f} [seg]\")\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nΔt={toc_-tic_:.1f}[seg]\"\n",
    "plt.suptitle(f'Barycentric Projection Interpolation with EMD Transport. {d_time}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path / f\"{additional_info}-barycentric-proj-interpolation-emd.png\", dpi=800)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Interpolación con la proyección baricéntrica particionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%time\n",
    "geodesic12 = PartitionedBarycentricProjGeodesic(\n",
    "    tpt.EMDTransport(max_iter=250_000), alpha=0.1\n",
    ").fit_wd(dd_s=dd1, dd_t=dd2)\n",
    "geodesic13 = PartitionedBarycentricProjGeodesic(\n",
    "    tpt.EMDTransport(max_iter=250_000), alpha=0.1\n",
    ").fit_wd(dd_s=dd1, dd_t=dd3)\n",
    "geodesic34 = PartitionedBarycentricProjGeodesic(\n",
    "    tpt.EMDTransport(max_iter=250_000), alpha=0.1\n",
    ").fit_wd(dd_s=dd3, dd_t=dd4)\n",
    "geodesic24 = PartitionedBarycentricProjGeodesic(\n",
    "    tpt.EMDTransport(max_iter=250_000), alpha=0.1\n",
    ").fit_wd(dd_s=dd2, dd_t=dd4)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "fig, axes = plt.subplots(nb_images, nb_images, figsize=(7, 7))\n",
    "cm = 'Blues'\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(nb_images):\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "        ty = float(j) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        tmp1 = (1 - tx) * v1 + tx * v2\n",
    "        tmp2 = (1 - tx) * v3 + tx * v4\n",
    "        weights = (1 - ty) * tmp1 + ty * tmp2\n",
    "\n",
    "        axes_ij = axes[i, j]\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            axes_ij.imshow(f1, cmap=cm)\n",
    "        elif i == 0 and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f3, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            axes_ij.imshow(f2, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f4, cmap=cm)\n",
    "        elif i == 0:\n",
    "            dd_t = DistributionDraw(*geodesic13.interpolate(ty), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif i == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic24.interpolate(ty), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == 0:\n",
    "            dd_t = DistributionDraw(*geodesic12.interpolate(tx), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic34.interpolate(tx), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        else:\n",
    "            axes_ij.imshow(np.zeros(original_shape), cmap=cm)\n",
    "        axes_ij.axis('off')\n",
    "\n",
    "        toc = time.time()\n",
    "        _log.debug(f\"{i = }, {j = } ==> Total time: {toc - tic:.4f} [seg]\")\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nΔt={toc_-tic_:.1f}[seg]\"\n",
    "plt.suptitle(f'Partitioned Barycentric Projection Interpolation with EMD Transport. {d_time}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path / f\"{additional_info}-barycentric-proj-interpolation-emd.png\", dpi=800)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Interpolación con Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%time\n",
    "kwargs = {\n",
    "    \"max_iter\": 250_000,\n",
    "    \"reg_e\": 1e-3,\n",
    "    \"norm\": \"max\"\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "geodesic12 = McCannGeodesic(tpt.SinkhornTransport(**kwargs)).fit_wd(dd_s=dd1, dd_t=dd2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "interp_param = {}\n",
    "# interp_param = {\n",
    "#     \"rtol\": ,\n",
    "#     \"atol\": 0,\n",
    "# }\n",
    "\n",
    "DistributionDraw(*geodesic12.interpolate(0.5, **interp_param), original_shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%time\n",
    "geodesic13 = McCannGeodesic(tpt.SinkhornTransport(**kwargs)).fit_wd(dd_s=dd1, dd_t=dd3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%time\n",
    "geodesic34 = McCannGeodesic(tpt.SinkhornTransport(**kwargs)).fit_wd(dd_s=dd3, dd_t=dd4)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%time\n",
    "geodesic24 = McCannGeodesic(tpt.SinkhornTransport(**kwargs)).fit_wd(dd_s=dd2, dd_t=dd4)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nb_images, nb_images, figsize=(7, 7))\n",
    "cm = 'Blues'\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(nb_images):\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "        ty = float(j) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        tmp1 = (1 - tx) * v1 + tx * v2\n",
    "        tmp2 = (1 - tx) * v3 + tx * v4\n",
    "        weights = (1 - ty) * tmp1 + ty * tmp2\n",
    "\n",
    "        axes_ij = axes[i, j]\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            axes_ij.imshow(f1, cmap=cm)\n",
    "        elif i == 0 and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f3, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            axes_ij.imshow(f2, cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == (nb_images - 1):\n",
    "            axes_ij.imshow(f4, cmap=cm)\n",
    "        elif i == 0:\n",
    "            dd_t = DistributionDraw(*geodesic13.interpolate(ty, **interp_param), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif i == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic24.interpolate(ty, **interp_param), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == 0:\n",
    "            dd_t = DistributionDraw(*geodesic12.interpolate(tx, **interp_param), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        elif j == (nb_images - 1):\n",
    "            dd_t = DistributionDraw(*geodesic34.interpolate(tx, **interp_param), original_shape)\n",
    "            axes_ij.imshow(dd_t.grayscale, cmap=cm)\n",
    "        else:\n",
    "            axes_ij.imshow(np.zeros(original_shape), cmap=cm)\n",
    "        axes_ij.axis('off')\n",
    "\n",
    "        toc = time.time()\n",
    "        _log.debug(f\"{i = }, {j = } ==> Total time: {toc - tic:.4f} [seg]\")\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nΔt={toc_-tic_:.1f}[seg]\"\n",
    "plt.suptitle(f'McCann Interpolation with Sinkhorn Transport. {d_time}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path / f\"{additional_info}-mccaan-interpolation-sinkhorn.png\", dpi=800)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
