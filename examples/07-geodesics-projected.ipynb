{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/codeProjects/pythonProjects/Bayesian-Learning-with-Wasserstein-Barycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bwb.config as cfg\n",
    "\n",
    "# cfg.use_single_precision()\n",
    "# cfg.use_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bwb\n",
    "from pathlib import Path\n",
    "\n",
    "main_path = Path(\".\")\n",
    "data_path = main_path / \"data\"\n",
    "face_path = data_path / \"face_recognized.npy\"\n",
    "face_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.load(face_path)\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwb.distributions.data_loaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = DistributionDrawDataLoader(arr, (28, 28))\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 4\n",
    "faces[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_, f2_ = faces[0], faces[indx]\n",
    "f1, f2 = f1_.grayscale_weights, f2_.grayscale_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from bwb.config import conf\n",
    "\n",
    "A = torch.stack([f1, f2])\n",
    "\n",
    "v1 = torch.tensor((1, 0, 0, 0), dtype=conf.dtype, device=conf.device)\n",
    "v2 = torch.tensor((0, 1, 0, 0), dtype=conf.dtype, device=conf.device)\n",
    "v3 = torch.tensor((0, 0, 1, 0), dtype=conf.dtype, device=conf.device)\n",
    "v4 = torch.tensor((0, 0, 0, 1), dtype=conf.dtype, device=conf.device)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from bwb.config import config\n",
    "from bwb import bregman\n",
    "\n",
    "eps = config.eps\n",
    "\n",
    "nb_images = 9\n",
    "fig, axes = plt.subplots(1, nb_images, figsize=(7, 2))\n",
    "cm = \"Blues\"\n",
    "# regularization parameter\n",
    "reg = 2e-3\n",
    "entrop_sharp = False\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(1):\n",
    "        ax = axes[i]\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        weights = (1 - tx) * torch.tensor(\n",
    "            [1, 0], device=conf.device\n",
    "        ) + tx * torch.tensor([0, 1], device=conf.device)\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            ax.imshow(f1.cpu(), cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            ax.imshow(f2.cpu(), cmap=cm)\n",
    "        else:\n",
    "            # call to barycenter computation\n",
    "            bar, log = bregman.convolutional_barycenter2d(\n",
    "                A,\n",
    "                reg,\n",
    "                weights,\n",
    "                # entrop_sharp=entrop_sharp,\n",
    "                numItermax=1_000,\n",
    "                stopThr=1e-8,\n",
    "                # verbose=True,\n",
    "                warn=False,\n",
    "                log=True,\n",
    "            )\n",
    "            bar = bar.cpu()\n",
    "            ax.imshow(bar, cmap=cm)\n",
    "        ax.set_title(f\"$t={weights[1].item():.2f}$\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        toc = time.time()\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nÎ”t={toc_-tic_:.1f}[seg]\"\n",
    "\n",
    "fig.suptitle(f\"Convolutional Wasserstein Barycenters.\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(img_path / f\"{additional_info}-entrop-sharp-{entrop_sharp}-conv-wasserstein-bar.png\",\n",
    "#             dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bwb.geodesics import *\n",
    "# from bwb.distributions import *\n",
    "# from bwb import transports as tpt\n",
    "\n",
    "# geodesic = PartitionedBarycentricProjGeodesic(\n",
    "#     tpt.EMDTransport(norm=\"max\", max_iter=5_000)\n",
    "# ).fit_wd(\n",
    "#     f1_, f2_,\n",
    "# )\n",
    "# geod, weights = geodesic.interpolate(0.5)\n",
    "# weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wgan_gp.wgan_gp_vae.model_resnet import Generator, Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 128\n",
    "CHANNELS_IMG = 1\n",
    "NUM_FILTERS = [256, 128, 64, 32]\n",
    "\n",
    "G = Generator(LATENT_DIM, CHANNELS_IMG).to(device)\n",
    "E = Encoder(LATENT_DIM, CHANNELS_IMG).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURR_PATH = Path(\".\")\n",
    "NETS_PATH = CURR_PATH / \"wgan_gp\" / \"networks\"\n",
    "# FACE_PATH = NETS_PATH / f\"_resnet_face_zDim{LATENT_DIM}_gauss_bs_128_recognized_augmented_WAE_WGAN_loss_l1_32p32\"\n",
    "FACE_PATH = NETS_PATH / \"data_cleaned_principal\"\n",
    "\n",
    "FACE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wgan_gp.wgan_gp_vae.utils import load_checkpoint\n",
    "\n",
    "load_checkpoint(G, FACE_PATH, \"generator\", device)\n",
    "load_checkpoint(E, FACE_PATH, \"encoder\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wgan_gp.wgan_gp_vae.utils import ProjectorOnManifold\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "proj = ProjectorOnManifold(\n",
    "    E,\n",
    "    G,\n",
    "    transform_in=T.Compose([\n",
    "        # From pdf to grayscale\n",
    "        T.Lambda(lambda x: x / torch.max(x)),\n",
    "        # T.Lambda(lambda x: x),\n",
    "        T.ToPILImage(),\n",
    "        T.Resize((32, 32)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(\n",
    "            [0.5 for _ in range(1)],\n",
    "            [0.5 for _ in range(1)],\n",
    "        ),\n",
    "    ]),\n",
    "    transform_out=T.Compose([\n",
    "        # Ensure the range is in [0, 1]\n",
    "        T.Lambda(lambda x: x - torch.min(x)),\n",
    "        T.Lambda(lambda x: x / torch.max(x)),\n",
    "        # T.Lambda(lambda x: 1 - x),\n",
    "        T.ToPILImage(),\n",
    "        T.Resize((28, 28)),\n",
    "        T.ToTensor(),\n",
    "        T.Lambda(lambda x: x / torch.sum(x)),\n",
    "        T.Lambda(lambda x: x.squeeze(0)),\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from bwb.config import config\n",
    "import ot\n",
    "\n",
    "eps = config.eps\n",
    "\n",
    "# nb_images = 7\n",
    "fig, axes = plt.subplots(2, nb_images, figsize=(7, 2))\n",
    "cm = \"Blues\"\n",
    "# regularization parameter\n",
    "reg = 0.01\n",
    "stopThr = 5e-4\n",
    "entrop_sharp = False\n",
    "tic_ = time.time()\n",
    "for i in range(nb_images):\n",
    "    for j in range(2):\n",
    "        ax = axes[j, i]\n",
    "        tic = time.time()\n",
    "\n",
    "        tx = float(i) / (nb_images - 1)\n",
    "\n",
    "        # weights are constructed by bilinear interpolation\n",
    "        weights = (1 - tx) * torch.tensor(\n",
    "            [1, 0], device=conf.device\n",
    "        ) + tx * torch.tensor([0, 1], device=conf.device)\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "            ax.imshow(f1.cpu(), cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 0:\n",
    "            ax.imshow(f2.cpu(), cmap=cm)\n",
    "        if i == 0 and j == 1:\n",
    "            ax.imshow(f1.cpu(), cmap=cm)\n",
    "        elif i == (nb_images - 1) and j == 1:\n",
    "            ax.imshow(f2.cpu(), cmap=cm)\n",
    "        elif j == 0:\n",
    "            # call to barycenter computation\n",
    "            bar, log = ot.bregman.convolutional_barycenter2d_debiased(\n",
    "                A,\n",
    "                reg,\n",
    "                weights,\n",
    "                # entrop_sharp=entrop_sharp,\n",
    "                # reg=0.01,\n",
    "                stopThr=stopThr,\n",
    "                # numItermax=1_000, stopThr=1e-8,\n",
    "                # verbose=True,\n",
    "                warn=False,\n",
    "                log=True,\n",
    "            )\n",
    "            # bar = proj(bar)\n",
    "            ax.imshow(bar.cpu(), cmap=cm)\n",
    "        elif j == 1:\n",
    "            # call to barycenter computation\n",
    "            bar, log = ot.bregman.convolutional_barycenter2d_debiased(\n",
    "                A,\n",
    "                reg,\n",
    "                weights,\n",
    "                # entrop_sharp=entrop_sharp,\n",
    "                # reg=0.01,\n",
    "                stopThr=stopThr,\n",
    "                # numItermax=1_000, stopThr=1e-8,\n",
    "                # verbose=True,\n",
    "                warn=False,\n",
    "                log=True,\n",
    "            )\n",
    "            bar = proj(bar)\n",
    "            ax.imshow(bar.cpu(), cmap=cm)\n",
    "        ax.set_title(f\"$t={weights[1].item():.2f}$\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        toc = time.time()\n",
    "toc_ = time.time()\n",
    "d_time = f\"\\nÎ”t={toc_-tic_:.1f}[seg]\"\n",
    "\n",
    "# plt.suptitle(f'Convolutional Wasserstein Barycenters in POT. {d_time}')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(img_path / f\"{additional_info}-entrop-sharp-{entrop_sharp}-conv-wasserstein-bar.png\",\n",
    "#             dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwb.distributions import DistributionDraw\n",
    "\n",
    "with torch.no_grad():\n",
    "    img = G(torch.randn(1, LATENT_DIM, 1, 1).to(device))\n",
    "    img = img.squeeze()\n",
    "    img = img - img.min()\n",
    "    img = img / img.sum()\n",
    "    dd = DistributionDraw.from_grayscale_weights(img)\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
