{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Configuraciones iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK = 5\n",
    "CLEAN_LOGS = True  # If you want to clean the logs directory\n",
    "SAVE_FIGS = True  # If you want to save the figures.\n",
    "NEW_DATA = False\n",
    "N_ROWS, N_COLS = 1, 6\n",
    "\n",
    "# MCMC Configurations\n",
    "RUN_MCMC = False\n",
    "BURN = 2_500\n",
    "NUM_SAMPLES = 25_000\n",
    "N_WALKERS = 16\n",
    "\n",
    "# Posterior\n",
    "N_DATA = 30\n",
    "\n",
    "REPORT_EVERY = 100  # To report at the logger\n",
    "PLOT_EVERY = 250\n",
    "MAX_ITER = 5_000  # MAx number of iterations for the SGDW\n",
    "BATCH_SIZE = 1\n",
    "PROJ_EVERY = None\n",
    "LIST_N_DATA = [5, 10, 25, 50]\n",
    "\n",
    "# MAX_ITER = 50; REPORT_EVERY = 5  # Descomentar para debuguear\n",
    "# BURN = 200\n",
    "# NUM_SAMPLES = 1_000\n",
    "# N_WALKERS = 2\n",
    "# LIST_N_DATA = [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from icecream import ic\n",
    "\n",
    "\n",
    "DS_NAME = \"data\"\n",
    "\n",
    "CURR_PATH = Path().absolute()\n",
    "ic(CURR_PATH)\n",
    "BASE_PATH = CURR_PATH.parent.parent\n",
    "ic(BASE_PATH)\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "ic(DATA_PATH)\n",
    "WGAN_PATH = BASE_PATH / \"wgan_gp\"\n",
    "ic(WGAN_PATH)\n",
    "NETS_PATH = WGAN_PATH / \"networks\"\n",
    "ic(NETS_PATH)\n",
    "IMGS_PATH = CURR_PATH / \"imgs\" / f\"notebook-{NOTEBOOK:02d}\"\n",
    "IMGS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "ic(IMGS_PATH)\n",
    "MCMC_PATH = BASE_PATH / \"saved_mcmc\"\n",
    "ic(MCMC_PATH)\n",
    "NUTS_PATH = MCMC_PATH / \"NUTS\"\n",
    "ic(NUTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(fig, name_to_save):\n",
    "    if SAVE_FIGS:\n",
    "        PATH_TO_SAVE = IMGS_PATH / name_to_save\n",
    "        fig.savefig(PATH_TO_SAVE.with_suffix(\".pdf\"))\n",
    "        fig.savefig(PATH_TO_SAVE.with_suffix(\".png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Importaciones generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "from bwb.sgdw import sgdw\n",
    "from bwb.sgdw import wrappers\n",
    "from bwb.sgdw import plotters as plotters_\n",
    "from bwb.distributions import *\n",
    "import bwb.utils.plotters as plotters\n",
    "import matplotlib.pyplot as plt\n",
    "from bwb.distributions.posterior_samplers import NUTSPosteriorSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Configuraciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwb.config import conf\n",
    "\n",
    "conf.use_gpu()\n",
    "conf.use_single_precision()\n",
    "conf.set_eps(1e-16)\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Configuración del Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Create the logs directory\n",
    "LOG_PATH = (\n",
    "    Path(\"logs\")\n",
    "    / f\"notebook-{NOTEBOOK:02d}_{time.strftime('%Y%m%d_%H%M%S')}.log\"\n",
    ")\n",
    "if not LOG_PATH.parent.exists():\n",
    "    LOG_PATH.parent.mkdir()\n",
    "\n",
    "# Clean the logs\n",
    "if CLEAN_LOGS:\n",
    "    for log_file in Path(\"logs\").glob(f\"notebook-{NOTEBOOK:02d}*.log\"):\n",
    "        log_file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from bwb.logging_ import log_config\n",
    "from bwb import logging_\n",
    "\n",
    "\n",
    "# Remove the handlers\n",
    "log_config.remove_all_handlers()\n",
    "ic(log_config.loggers)\n",
    "\n",
    "# Define and add FileHandler\n",
    "fh = logging.FileHandler(LOG_PATH)\n",
    "log_config.add_handler(fh)\n",
    "\n",
    "\n",
    "_log = log_config.get_logger(\"notebook\")\n",
    "log_config.set_level(level=logging.DEBUG, name=\"notebook\")\n",
    "log_config.set_level(level=logging.DEBUG, name=\"bwb.sgdw.sgdw\")\n",
    "log_config.set_level(level=logging.DEBUG, name=\"bwb.sgdw.plotters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Esta celda es para configurar la información mostrada en el logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default options for the report\n",
    "wrappers.ReportProxy.INCLUDE_OPTIONS = wrappers.ReportOptions(\n",
    "    dt=False,\n",
    "    dt_per_iter=True,\n",
    "    iter=True,\n",
    "    step_schd=True,\n",
    "    total_time=True,\n",
    "    w_dist=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Obtención del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the wrapper to transform the usual DataSet into a model set\n",
    "from bwb.distributions.models import ModelDataset\n",
    "import quick_torch as qt\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "transform_ds = T.Compose([\n",
    "    T.Resize((32, 32)),\n",
    "    T.ToImage(),\n",
    "    T.ToDtype(conf.dtype, scale=True),\n",
    "    T.Lambda(lambda x: x.squeeze()),\n",
    "])\n",
    "\n",
    "\n",
    "def get_ds(file_path, transform=transform_ds):\n",
    "    ic(file_path)\n",
    "    categories = [qt.Category.FACE]\n",
    "    dataset_ = qt.QuickDraw(\n",
    "        root=DATA_PATH,\n",
    "        categories=categories,\n",
    "        transform=transform,\n",
    "        download=True,\n",
    "        recognized=True,\n",
    "    )\n",
    "    path_dataset = Path(file_path)\n",
    "    dataset_.data = np.load(path_dataset).reshape(-1, 28, 28)\n",
    "    dataset_.targets = np.ones(len(dataset_.data), dtype=int)\n",
    "    dataset = dataset_.get_train_data()\n",
    "    ic(len(dataset))\n",
    "\n",
    "    return ModelDataset(dataset)\n",
    "\n",
    "\n",
    "DS_PATH = WGAN_PATH / \"dataset\" / \"cleaned\" / f\"{DS_NAME}.npy\"\n",
    "ds_models = get_ds(DS_PATH)\n",
    "ds_dist_sampler = UniformDiscreteSampler().fit(ds_models)\n",
    "\n",
    "i = 37\n",
    "first_face = ds_models.get(i)\n",
    "fig, _ = plotters.plot_draw(first_face, title=f\"Cara $i={i}$\")\n",
    "save_fig(fig, \"first_face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quick_torch import QuickDraw\n",
    "import torchvision.transforms.v2 as T\n",
    "from pathlib import Path\n",
    "\n",
    "transforms = T.Compose([\n",
    "    T.ToImage(),\n",
    "    T.Resize(32),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Lambda(lambda x: x.squeeze()),\n",
    "])\n",
    "\n",
    "ds = QuickDraw(\n",
    "    DATA_PATH,\n",
    "    categories=\"face\",\n",
    "    download=True,\n",
    "    transform=transforms,\n",
    ")\n",
    "\n",
    "# You can use the wrapper to transform the usual DataSet into a model set\n",
    "from bwb.distributions.models import ModelDataset\n",
    "\n",
    "ds = ModelDataset(ds)\n",
    "\n",
    "from bwb.distributions.distribution_samplers import UniformDiscreteSampler\n",
    "\n",
    "ds_sampler = UniformDiscreteSampler().fit(ds)\n",
    "\n",
    "i = 37\n",
    "first_face = ds.get(i)\n",
    "print(first_face.shape)\n",
    "_ = plotters.plot_draw(first_face, title=f\"Cara $i={i}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Obtener data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = first_face.sample((1_000,))[:N_DATA]\n",
    "\n",
    "shape = first_face.shape\n",
    "data_coords = (\n",
    "    first_face.enumerate_support_()[data].cpu().numpy()\n",
    "    + np.random.randn(len(data), 2) * 0.1\n",
    ")\n",
    "\n",
    "plotters.plot_histogram_from_points(\n",
    "    data_coords, rotate=True, shape=shape, histplot_kwargs=dict(bins=shape[0])\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "POST_DATA_PATH = CURR_PATH / \"data\"  # / f\"n_data-{N_DATA}.pkl\"\n",
    "POST_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PATH_ = POST_DATA_PATH / f\"data-{i}.pkl\"\n",
    "print(DATA_PATH_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_hist(\n",
    "    face,\n",
    "    data,\n",
    "    n_data=None,\n",
    "    plot=True,\n",
    "    exp=None,\n",
    "    title=\"Imagen de la cara a muestrear\",\n",
    "    hist_title=\"$n={}$ muestras a partir de la imagen\",\n",
    "):\n",
    "    data_ = data.clone()\n",
    "    if n_data is None:\n",
    "        n_data = len(data)\n",
    "    else:\n",
    "        data = data[:n_data]\n",
    "\n",
    "    shape = face.shape\n",
    "    data_coords = (\n",
    "        face.enumerate_support_()[data].cpu().numpy()\n",
    "        + np.random.randn(n_data, 2) * 0.1\n",
    "    )\n",
    "\n",
    "    if plot:\n",
    "        fig_ax1 = plotters.plot_draw(face, title=title)\n",
    "        ax2 = plotters.plot_histogram_from_points(\n",
    "            data_coords,\n",
    "            title=hist_title.format(n_data),\n",
    "            rotate=True,\n",
    "            shape=shape,\n",
    "            histplot_kwargs=dict(bins=shape[0]),\n",
    "        )\n",
    "\n",
    "    return face, data_, fig_ax1, ax2\n",
    "\n",
    "\n",
    "def get_data(\n",
    "    face,\n",
    "    n_data,\n",
    "    plot=True,\n",
    "    exp=None,\n",
    "    title=\"Imagen de la cara a muestrear\",\n",
    "    hist_title=\"$n={}$ muestras a partir de la imagen\",\n",
    "):\n",
    "    data = face.sample((n_data,))\n",
    "\n",
    "    return plot_img_hist(face, data, n_data, plot, exp, title, hist_title)\n",
    "\n",
    "\n",
    "def get_sampler(\n",
    "    sampler,\n",
    "    n_data,\n",
    "    plot=True,\n",
    "    exp=None,\n",
    "    title=\"Face sampled from dataset\",\n",
    "    hist_title=\"Histogram of the distribution generated by a drawing\",\n",
    "):\n",
    "    return get_data(sampler.draw(), n_data, plot, exp, title, hist_title)\n",
    "\n",
    "\n",
    "# _, _, (fig1, ax1), (fig2, ax2) = get_sampler(ds_sampler, 100)\n",
    "_, data, (fig1, ax1), (fig2, ax2) = get_data(first_face, 100)\n",
    "\n",
    "import pickle\n",
    "\n",
    "if NEW_DATA or not DATA_PATH_.exists():\n",
    "    print(\"Salvando data...\")\n",
    "    with open(DATA_PATH_, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    print(\"Obteniendo data...\")\n",
    "    with open(DATA_PATH_, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "_ = plot_img_hist(first_face, data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Obtener GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "De la misma manera, se puede definir un muestreador de distribuciones utilizando una GAN. Para ello, empezamos definiendo las redes neuronales a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wgan_gp.wgan_gp_vae.model_resnet import (\n",
    "    Generator,\n",
    "    Encoder,\n",
    "    LatentDistribution,\n",
    ")\n",
    "import torch\n",
    "from wgan_gp.wgan_gp_vae.utils import load_checkpoint\n",
    "\n",
    "\n",
    "device = conf.device\n",
    "\n",
    "NOISE = \"norm\"\n",
    "LATENT_DIM = 128\n",
    "CHANNELS_IMG = 1\n",
    "NUM_FILTERS = [256, 128, 64, 32]\n",
    "\n",
    "noise_sampler = LatentDistribution(NOISE, LATENT_DIM, device)\n",
    "\n",
    "\n",
    "G = Generator(LATENT_DIM, CHANNELS_IMG, latent_distr=NOISE).to(device)\n",
    "E = Encoder(LATENT_DIM, CHANNELS_IMG).to(device)\n",
    "\n",
    "DS_NAME = \"data\"\n",
    "FACE_PATH = NETS_PATH / f\"cleaned_{DS_NAME}_zDim{LATENT_DIM}_{NOISE}_bs_128\"\n",
    "ic(FACE_PATH)\n",
    "\n",
    "load_checkpoint(G, FACE_PATH, \"generator\", device)\n",
    "load_checkpoint(E, FACE_PATH, \"encoder\", device)\n",
    "\n",
    "G.eval()\n",
    "E.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwb.distributions import DistributionDraw\n",
    "from torchvision import disable_beta_transforms_warning\n",
    "\n",
    "disable_beta_transforms_warning()\n",
    "\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "\n",
    "z = noise_sampler(1)\n",
    "m = G(z)\n",
    "\n",
    "transform_in = T.Compose([\n",
    "    T.Lambda(lambda x: x / torch.max(x)),\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(32),\n",
    "    T.ToImage(),\n",
    "    T.ConvertImageDtype(conf.dtype),\n",
    "    T.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "transform_out_ = T.Compose([\n",
    "    T.ToDtype(conf.dtype),\n",
    "    T.Lambda(lambda x: x.squeeze()),\n",
    "    T.Lambda(lambda x: x - torch.min(x)),\n",
    "    T.Lambda(lambda x: x / torch.sum(x)),\n",
    "])\n",
    "\n",
    "transform_out = T.Compose([\n",
    "    transform_out_,\n",
    "    T.Lambda(lambda x: DistributionDraw.from_grayscale_weights(x)),\n",
    "])\n",
    "\n",
    "\n",
    "out: DistributionDraw = transform_out(m)\n",
    "print(out.dtype)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Definir Proyector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wgan_gp.wgan_gp_vae.utils import ProjectorOnManifold\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "transform_in_proj = T.Compose([\n",
    "    # From pdf to grayscale\n",
    "    T.Lambda(lambda x: x / torch.max(x)),\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((32, 32)),\n",
    "    T.ToImage(),\n",
    "    T.ToDtype(conf.dtype, scale=True),\n",
    "    T.Normalize(\n",
    "        [0.5 for _ in range(1)],\n",
    "        [0.5 for _ in range(1)],\n",
    "    ),\n",
    "])\n",
    "\n",
    "transform_out_proj = T.Compose([\n",
    "    # Ensure the range is in [0, 1]\n",
    "    T.Lambda(lambda x: x - torch.min(x)),\n",
    "    T.Lambda(lambda x: x / torch.max(x)),\n",
    "    T.Lambda(lambda x: x / torch.sum(x)),\n",
    "    T.Lambda(lambda x: x.squeeze(0)),\n",
    "])\n",
    "\n",
    "_proj = ProjectorOnManifold(\n",
    "    E,\n",
    "    G,\n",
    "    transform_in=transform_in_proj,\n",
    "    transform_out=transform_out_proj,\n",
    ")\n",
    "\n",
    "\n",
    "def proj(input_: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Defines a projector using the interface.\n",
    "    \"\"\"\n",
    "    return _proj(input_).to(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Definir $\\gamma_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Aquí se utiliza una función de la forma\n",
    "\\begin{equation*}\n",
    "    \\gamma_k = \\frac{a}{(b^{1/c} + k)^c}\n",
    "\\end{equation*}\n",
    "\n",
    "Con $a > 0$, $b \\geq 0$ y $0.5 < c \\leq 1$\n",
    "\n",
    "La idea es que cuando $k=0$, $\\gamma_0 = \\frac{a}{b}$ es la proporción entre $a$ y $b$, permitiendo ajustar el valor inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwb.sgdw.utils import step_scheduler\n",
    "\n",
    "window = 5\n",
    "\n",
    "\n",
    "def test_gamma(gamma):\n",
    "\n",
    "    for t in range(window):\n",
    "        print(f\"{t = :_}; {gamma(t) = :.2%}\")\n",
    "    print()\n",
    "\n",
    "    init = 50\n",
    "    for t in range(init, init + window):\n",
    "        print(f\"{t = :_}; {gamma(t) = :.2%}\")\n",
    "    print()\n",
    "\n",
    "    init = 100\n",
    "    for t in range(init, init + window):\n",
    "        print(f\"{t = :_}; {gamma(t) = :.2%}\")\n",
    "    print()\n",
    "\n",
    "    init = 300\n",
    "    for t in range(init, init + window):\n",
    "        print(f\"{t = :_}; {gamma(t) = :.2%}\")\n",
    "    print()\n",
    "\n",
    "    init = 500\n",
    "    for t in range(init, init + window):\n",
    "        print(f\"{t = :_}; {gamma(t) = :.2%}\")\n",
    "    print()\n",
    "\n",
    "    init = 1_000\n",
    "    for t in range(init, init + window):\n",
    "        print(f\"{t = :_}; {gamma(t) = :.2%}\")\n",
    "    print()\n",
    "\n",
    "    init = 3_000\n",
    "    for t in range(init, init + window):\n",
    "        print(f\"{t = :_}; {gamma(t) = :.2%}\")\n",
    "    print()\n",
    "\n",
    "    init = 5_000\n",
    "    for t in range(init, init + window):\n",
    "        print(f\"{t = :_}; {gamma(t) = :.2%}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "_a = 3\n",
    "_eps = 1e-3\n",
    "params = dict(a=_a, b=_a + 1e-2, c=0.5 + _eps)\n",
    "# params = dict(a=1, b=1, c=1)\n",
    "\n",
    "gamma = step_scheduler(**params)\n",
    "\n",
    "test_gamma(step_scheduler(**params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Definir distribución a posteriori con MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS_POSTERIOR_PATH = (\n",
    "    NUTS_PATH\n",
    "    / f\"bayes-bar-i={i}-n_data-{N_DATA}-burn-{BURN:_}-num_samples-{NUM_SAMPLES:_}-n_walkers-{N_WALKERS}\"\n",
    ")\n",
    "NUTS_POSTERIOR_PATH = NUTS_POSTERIOR_PATH.with_suffix(\".pkl.gz\")\n",
    "print(NUTS_POSTERIOR_PATH)\n",
    "\n",
    "POST_DATA_PATH = CURR_PATH / \"data\"  # / f\"n_data-{N_DATA}.pkl\"\n",
    "POST_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PATH_ = (\n",
    "    POST_DATA_PATH\n",
    "    / f\"i-{i}-n_data-{N_DATA}-burn-{BURN:_}-num_samples-{NUM_SAMPLES:_}-n_walkers-{N_WALKERS}.pkl\"\n",
    ")\n",
    "print(DATA_PATH_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "\n",
    "NUTS_PARAMS = dict(\n",
    "    n_walkers=N_WALKERS,\n",
    "    num_steps_per_sample=1,\n",
    "    burn=BURN,\n",
    "    desired_accept_rate=0.6,\n",
    "    use_half=True,\n",
    ")\n",
    "\n",
    "RUN_PARAMS = dict(\n",
    "    n_steps=NUM_SAMPLES,\n",
    ")\n",
    "\n",
    "MCMC_PLOT_PARAMS = dict(\n",
    "    n_rows=3,\n",
    "    n_cols=6,\n",
    ")\n",
    "\n",
    "\n",
    "def save_fig(fig, name_to_save: str, imgs_path=IMGS_PATH):\n",
    "    path_to_save = imgs_path / name_to_save\n",
    "    fig.savefig(path_to_save.with_suffix(\".pdf\"), bbox_inches=\"tight\")\n",
    "    fig.savefig(path_to_save.with_suffix(\".png\"), bbox_inches=\"tight\")\n",
    "    print(\"Images saved with name\", name_to_save)\n",
    "\n",
    "\n",
    "def run_mcmc_experiment(\n",
    "    face,\n",
    "    data,\n",
    "    n_data,\n",
    "    thin=None,\n",
    "    nuts_params=NUTS_PARAMS,\n",
    "    run_params=RUN_PARAMS,\n",
    "    mcmc_plot_params=MCMC_PLOT_PARAMS,\n",
    "    run_mcmc=RUN_MCMC,\n",
    "    mcmc_path=NUTS_PATH,\n",
    "):\n",
    "    # Constants\n",
    "    burn = nuts_params.get(\"burn\", None)\n",
    "    num_samples = run_params.get(\"n_steps\", None)\n",
    "    n_walkers = nuts_params.get(\"n_walkers\", None)\n",
    "    n_rows = mcmc_plot_params.get(\"n_rows\", N_ROWS)\n",
    "    n_cols = mcmc_plot_params.get(\"n_cols\", N_COLS)\n",
    "\n",
    "    # Path to save the chain\n",
    "    mcmc_2_save_path = (\n",
    "        mcmc_path\n",
    "        / f\"n-{n_data}-burn-{burn:_}-num_samples-{num_samples:_}-n_walkers-{n_walkers}\"\n",
    "    )\n",
    "    mcmc_2_save_path = mcmc_2_save_path.with_suffix(\".pkl.gz\")\n",
    "\n",
    "    # Getting the data\n",
    "    data = data.clone()[:n_data]\n",
    "    face, data, (fig1, _), (hist1, _) = plot_img_hist(face, data, n_data)\n",
    "    print(f\"{data.shape=}\")\n",
    "\n",
    "    # Train the MCMC, or load if there are one in the cache\n",
    "    if not mcmc_2_save_path.exists() or run_mcmc:\n",
    "        post_pi_n = NUTSPosteriorSampler(**nuts_params).fit(\n",
    "            G,\n",
    "            transform_out_,\n",
    "            noise_sampler,\n",
    "            data,\n",
    "        )\n",
    "\n",
    "        post_pi_n.run(**run_params)\n",
    "\n",
    "        tic = time.perf_counter()\n",
    "        post_pi_n.save(mcmc_2_save_path)\n",
    "        toc = time.perf_counter()\n",
    "        ic(toc - tic)\n",
    "\n",
    "    else:\n",
    "        post_pi_n = NUTSPosteriorSampler.load(mcmc_2_save_path)\n",
    "        post_pi_n.fit(G, transform_out_, noise_sampler, data)\n",
    "\n",
    "    # Computing the mean autocorr time\n",
    "    mean_autocorr_time = int(post_pi_n.get_autocorr_time().mean())\n",
    "    print(f\"{mean_autocorr_time=}\")\n",
    "\n",
    "    title = (\n",
    "        \"Muestras del MCMC para \"\n",
    "        + r\"$n = \"\n",
    "        + f\"{n_data}$, \\n\"\n",
    "        + r\"$\\hat\\tau_\\mathrm{mean}\"\n",
    "        + f\"={mean_autocorr_time}$\"\n",
    "    )\n",
    "    mcmc_plot_params.update({\"title\": title})\n",
    "\n",
    "    post_pi_n.shuffle_samples_cache(thin=thin or int(mean_autocorr_time))\n",
    "\n",
    "    # Plot some samples form the posterior\n",
    "    max_imgs = n_rows * n_cols\n",
    "    fig2, ax = plotters.plot_list_of_draws(\n",
    "        post_pi_n.sample(max_imgs), **mcmc_plot_params\n",
    "    )\n",
    "\n",
    "    return post_pi_n, (fig1, hist1, fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_POST_PI_N = []\n",
    "post_pi_n = None\n",
    "\n",
    "for n in LIST_N_DATA:\n",
    "    # Ejecutar MCMC\n",
    "    print(\"Ejecutando la cadena con n =\", n)\n",
    "    post_pi_n, (fig_mcmc, hist_mcmc, fig_samples) = run_mcmc_experiment(\n",
    "        first_face,\n",
    "        data,\n",
    "        n,\n",
    "        thin=None,\n",
    "    )\n",
    "\n",
    "    LIST_POST_PI_N.append(post_pi_n)\n",
    "\n",
    "    # Calcular baricentro\n",
    "    # SGDW con la posterior\n",
    "    dist_draw_sgdw = wrappers.ReportProxy(\n",
    "        sgdw.DebiesedDistributionDrawSGDW(\n",
    "            distr_sampler=post_pi_n,\n",
    "            step_scheduler=gamma,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            max_iter=int(min(MAX_ITER, post_pi_n.n_cached_samples - 1)),\n",
    "        ),\n",
    "        report_every=REPORT_EVERY,\n",
    "        log=_log,\n",
    "    )\n",
    "\n",
    "    # Plotter\n",
    "    plotter_comp = plotters_.PlotterComparison(\n",
    "        dist_draw_sgdw,\n",
    "        # projector=proj,\n",
    "        # proj_every=PROJ_EVERY,\n",
    "        n_cols=N_COLS,\n",
    "        n_rows=N_ROWS,\n",
    "        cmap=\"binary_r\",\n",
    "        plot_every=PLOT_EVERY,\n",
    "    )\n",
    "\n",
    "    # Correr el plotter\n",
    "    _log.info(\n",
    "        f\"Running SGD-Wasserstein with '{DS_NAME}' bayesian projected\"\n",
    "        \" barycenter\"\n",
    "    )\n",
    "    with logging_.register_total_time(_log) as timer:\n",
    "        bar = plotter_comp.run()\n",
    "\n",
    "    fig_first_iter, _ = plotter_comp.plot(0)\n",
    "    save_fig(fig_first_iter, f\"first-iters-n-data-{n}\")\n",
    "\n",
    "    fig_last_iter, _ = plotter_comp.plot()\n",
    "    save_fig(fig_last_iter, f\"last-iters-n-data-{n}\")\n",
    "\n",
    "    fig_bwb, _ = plotters.plot_draw(bar, title=r\"BWB with $n={}$\".format(n))\n",
    "    save_fig(fig_bwb, f\"BWB-n-data-{n}\")\n",
    "\n",
    "    if SAVE_FIGS:\n",
    "        save_fig(fig_mcmc, f\"image-sampler-i-{i}\")\n",
    "        save_fig(hist_mcmc, f\"samples-hist-n-{n}\")\n",
    "        post_name = post_pi_n.__class__.__name__\n",
    "        save_fig(fig_samples, f\"mcmc-n-{n}-{post_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape = first_face.shape\n",
    "# data_coords = first_face.enumerate_support_()[data].cpu().numpy() + np.random.randn(len(data), 2) * 0.1\n",
    "#\n",
    "# fig, _ = plotters.plot_histogram_from_points(data_coords, rotate=True, shape=shape, histplot_kwargs=dict(bins=shape[0]))\n",
    "# save_fig(fig, f\"n_data-{N_DATA}\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_pi_n.mean_autocorr_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_autocorr_time = int(autocorr_time.mean())\n",
    "# ic(mean_autocorr_time)\n",
    "# max_autocorr_time = int(autocorr_time.max())\n",
    "# ic(max_autocorr_time)\n",
    "\n",
    "# post_pi_n.shuffle_samples_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from copy import copy\n",
    "# post_pi_n_ = copy(post_pi_n)\n",
    "# n_rows, n_cols = 6, 12\n",
    "# max_imgs = n_rows * n_cols\n",
    "# fig, ax = plotters.plot_list_of_draws(\n",
    "#     post_pi_n_.sample(max_imgs),\n",
    "#     n_rows=n_rows, n_cols=n_cols,\n",
    "#     title=f\"Muestras a partir del MCMC con \"\n",
    "# )\n",
    "# save_fig(fig, f\"n-data-{N_DATA}-{post_pi_n.__class__.__name__}-{n_rows}x{n_cols}\")\n",
    "# del post_pi_n_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "# Cálculo del Baricentro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist_draw_sgdw = wrappers.ReportProxy(\n",
    "#     sgdw.DebiesedDistributionDrawSGDW(\n",
    "#         distr_sampler=post_pi_n,\n",
    "#         step_scheduler=gamma,\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         max_iter=int(min(MAX_ITER, post_pi_n.n_cached_samples - 1)),\n",
    "#     ),\n",
    "#     report_every=REPORT_EVERY,\n",
    "#     log=_log\n",
    "# )\n",
    "# dist_draw_sgdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotter_comp = plotters_.PlotterComparison(\n",
    "#     dist_draw_sgdw,\n",
    "#     # projector=proj,\n",
    "#     # proj_every=PROJ_EVERY,\n",
    "#     n_cols=N_COLS,\n",
    "#     n_rows=N_ROWS,\n",
    "#     cmap=\"binary_r\",\n",
    "#     plot_every=PLOT_EVERY,\n",
    "# )\n",
    "# plotter_comp.sgdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _log.info(f\"Running SGD-Wasserstein with '{DS_NAME}' bayesian projected barycenter\")\n",
    "# with logging_.register_total_time(_log) as timer:\n",
    "#     bar = plotter_comp.run()\n",
    "# ic(timer.elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotter_comp.sgdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, _ = plotter_comp.plot(0)\n",
    "# save_fig(fig, F\"first-iters-n-data-{N_DATA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, _ = plotter_comp.plot()\n",
    "# save_fig(fig, f\"last-iters-n-data-{N_DATA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, _ = plotters.plot_draw(bar, title=r\"BWB with $n={}$\".format(N_DATA))\n",
    "# save_fig(fig, f\"BWB-n-data-{N_DATA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
