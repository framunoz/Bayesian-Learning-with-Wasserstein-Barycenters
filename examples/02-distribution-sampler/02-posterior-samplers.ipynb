{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ecd3527-3304-49df-8e19-a2643dbb711c",
   "metadata": {},
   "source": [
    "# Constantes y Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1220d9ee-0c84-4487-ad07-82b6af5e6425",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# %cd ~/codeProjects/pythonProjects/Bayesian-Learning-with-Wasserstein-Barycenters"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b88a01-d00d-4602-aa7d-5becdd03ef78",
   "metadata": {},
   "source": [
    "SAVE_FIGS = True  # If you want to save the figures.\n",
    "RUN_MCMC = False  # If you want to run the MCMC's algorithms or use saved chains"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d4b145-37d1-47e2-b9f9-46e8de44075e",
   "metadata": {},
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from icecream import ic\n",
    "import time\n",
    "\n",
    "import bwb.plotters as plotters"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f5e10a-6739-470a-89ea-3cacc64babe8",
   "metadata": {},
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65560e8c-c1b0-4592-b7f3-bd9e8157d81a",
   "metadata": {},
   "source": [
    "from bwb import _logging as logging\n",
    "\n",
    "log = logging.get_logger(__name__)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6525dac6-1cda-4eff-aaf9-d908468ab724",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CURR_PATH = Path().absolute()\n",
    "print(f\"{CURR_PATH = }\")\n",
    "BASE_PATH = CURR_PATH.parent.parent\n",
    "print(f\"{BASE_PATH = }\")\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "print(f\"{DATA_PATH = }\")\n",
    "NETS_PATH = BASE_PATH / \"wgan_gp\" / \"networks\" \n",
    "print(f\"{NETS_PATH = }\")\n",
    "IMGS_PATH = CURR_PATH / \"imgs\" / \"notebook-02\"\n",
    "IMGS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"{IMGS_PATH = }\")\n",
    "MCMC_PATH = BASE_PATH / \"saved_mcmc\"\n",
    "print(f\"{MCMC_PATH = }\")\n",
    "NUTS_PATH = MCMC_PATH / \"NUTS\"\n",
    "print(f\"{NUTS_PATH = }\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d9d2ccc-a71d-46e5-8e78-aaa4692f7038",
   "metadata": {},
   "source": [
    "from bwb.config import conf\n",
    "\n",
    "conf.use_single_precision()\n",
    "conf.set_eps(1e-20)\n",
    "conf"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a5682796-b013-47f7-a260-7c6a54948591",
   "metadata": {},
   "source": [
    "# Sampleador de Distribuciones Posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f44dc9-d739-4366-86d4-435af0f9200d",
   "metadata": {},
   "source": [
    "Al igual que los muestreadores de distribuciones anteriores, los muestreadores a posteriori heredan de `bwb.distributions.distribution_samplers.DistributionSampler`. En este caso, tenemos a la clase abstracta\n",
    "`bwb.distributions.posterior_samplers.BaseLatentMCMCPosteriorSampler` que define un MCMC utilizando la librería `hamiltorch`.\n",
    "\n",
    "Al igual que en `bwb.distributions.distribution_samplers.GeneratorDistribSampler`, la forma de ajustar esta clase es con un generador `generator`, una transformación `transform_out`, un muestreador de ruido `noise_sampler` y datos para la posterior `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb15f8-c7ce-4ae7-851e-2653e675b74f",
   "metadata": {},
   "source": [
    "## Obtener el modelo para muestrear los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a375ae-7cc3-47e6-bf04-a0361953ce73",
   "metadata": {},
   "source": [
    "Definimos el Dataset para obtener la primera cara y poder muestrear de ella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9aa750-5ea0-4bd5-bb67-247e105b757f",
   "metadata": {},
   "source": [
    "from quick_torch import QuickDraw\n",
    "import torchvision.transforms.v2 as T\n",
    "from pathlib import Path\n",
    "\n",
    "transforms = T.Compose([\n",
    "    T.ToImage(),\n",
    "    T.Resize(32),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Lambda(lambda x: x.squeeze()),\n",
    "])\n",
    "\n",
    "ds = QuickDraw(\n",
    "    DATA_PATH,\n",
    "    categories=\"face\",\n",
    "    download=True,\n",
    "    transform=transforms,\n",
    ")\n",
    "\n",
    "# You can use the wrapper to transform the usual DataSet into a model set\n",
    "from bwb.distributions.models import ModelDataset\n",
    "\n",
    "ds = ModelDataset(ds)\n",
    "\n",
    "first_face = ds.get(0)\n",
    "print(first_face.shape)\n",
    "_ = plotters.plot_draw(ds.get(0), title=\"First face\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "300e1d08-029f-460a-a681-fc7f39c7cc6c",
   "metadata": {},
   "source": [
    "Obtenemos una muestra y lo graficamos en un histograma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c87f85-017b-4a27-812c-d0dd66dd65e4",
   "metadata": {},
   "source": [
    "## Obtener data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51f0d292-f194-467a-96ec-bda4460d6331",
   "metadata": {},
   "source": [
    "N_DATA = 100\n",
    "data = first_face.sample((N_DATA,))\n",
    "\n",
    "shape = first_face.shape\n",
    "data_coords = first_face.enumerate_support_()[data].cpu().numpy() + np.random.randn(len(data), 2) * 0.1\n",
    "\n",
    "plotters.plot_histogram_from_points(data_coords, rotate=True, shape=shape, histplot_kwargs=dict(bins=shape[0]))\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "33f6b2fd-ef8a-45d2-a70d-0814f2d02ed0",
   "metadata": {},
   "source": [
    "# Definir red neuronal generadora y transformador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50031acf-7f76-4034-a231-531345a89f65",
   "metadata": {},
   "source": [
    "Se define la red neuronal de la misma manera que en el notebook anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5332c5eb-0562-4744-84b1-5de9b094a901",
   "metadata": {},
   "source": [
    "from wgan_gp.wgan_gp_vae.model_resnet import Generator, Encoder, LatentDistribution\n",
    "import torch\n",
    "from wgan_gp.wgan_gp_vae.utils import load_checkpoint\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "NOISE = \"norm\"\n",
    "LATENT_DIM = 128\n",
    "CHANNELS_IMG = 1\n",
    "NUM_FILTERS = [256, 128, 64, 32]\n",
    "\n",
    "noise_sampler = LatentDistribution(NOISE, LATENT_DIM, device)\n",
    "\n",
    "G = Generator(LATENT_DIM, CHANNELS_IMG, latent_distr=NOISE).to(device)\n",
    "E = Encoder(LATENT_DIM, CHANNELS_IMG).to(device)\n",
    "\n",
    "DS_NAME = \"data\"\n",
    "FACE_PATH = NETS_PATH / f\"cleaned_{DS_NAME}_zDim{LATENT_DIM}_{NOISE}_bs_128\"\n",
    "\n",
    "load_checkpoint(G, FACE_PATH, \"generator\", device)\n",
    "load_checkpoint(E, FACE_PATH, \"encoder\", device)\n",
    "\n",
    "G.eval(); E.eval()\n",
    "print()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba7bf9cd-a362-4172-836a-39da2586c4f9",
   "metadata": {},
   "source": [
    "from bwb.distributions import DistributionDraw\n",
    "from torchvision import disable_beta_transforms_warning\n",
    "disable_beta_transforms_warning()\n",
    "\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "\n",
    "z = noise_sampler(1)\n",
    "m = G(z)\n",
    "\n",
    "transform_in = T.Compose([\n",
    "    T.Lambda(lambda x: x / torch.max(x)),\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(32),\n",
    "    T.ToImage(),\n",
    "    T.ConvertImageDtype(torch.float32),\n",
    "    T.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "transform_out_ = T.Compose([\n",
    "    T.ToDtype(torch.float64),\n",
    "    T.Lambda(lambda x: x.squeeze()),\n",
    "    T.Lambda(lambda x: x - torch.min(x)),\n",
    "    T.Lambda(lambda x: x / torch.sum(x)),\n",
    "])\n",
    "\n",
    "transform_out = T.Compose([\n",
    "    transform_out_,\n",
    "    T.Lambda(lambda x: DistributionDraw.from_grayscale_weights(x)),\n",
    "])\n",
    "\n",
    "out: DistributionDraw = transform_out(m)\n",
    "print(out.dtype)\n",
    "out"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c0d25929-8785-41c6-bcf4-d1c87245c625",
   "metadata": {},
   "source": [
    "# Definir el muestreador de distribuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "044cba24-3c01-43b0-8ffe-68106d0bfd70",
   "metadata": {},
   "source": [
    "BURN = 2_000\n",
    "NUM_SAMPLES = 10_000\n",
    "N_WALKERS = 1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "787f5342-7029-4ed1-b8dc-cd3954083d1f",
   "metadata": {},
   "source": [
    "from bwb.distributions.posterior_samplers import NUTSPosteriorSampler"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "babc9b42-178e-4e7f-add5-3f9e086476bb",
   "metadata": {},
   "source": [
    "NUTS_POSTERIOR_PATH = NUTS_PATH / f\"burn-{BURN:_}-num_samples-{NUM_SAMPLES:_}-n_walkers-{N_WALKERS}\"\n",
    "NUTS_POSTERIOR_PATH = NUTS_POSTERIOR_PATH.with_suffix(\".pkl.gz\")\n",
    "print(NUTS_POSTERIOR_PATH)\n",
    "\n",
    "if not NUTS_POSTERIOR_PATH.exists() or RUN_MCMC:\n",
    "    post_pi_n = NUTSPosteriorSampler(\n",
    "        n_walkers=N_WALKERS,\n",
    "        num_steps_per_sample=1,\n",
    "        burn=BURN,\n",
    "        desired_accept_rate=0.6,\n",
    "    ).fit(\n",
    "        G, transform_out_, noise_sampler, data,\n",
    "    )\n",
    "    \n",
    "    post_pi_n.run(\n",
    "        n_steps=NUM_SAMPLES,\n",
    "    )\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    post_pi_n.save(NUTS_POSTERIOR_PATH)\n",
    "    toc = time.perf_counter()\n",
    "    ic(toc - tic)\n",
    "    \n",
    "else:\n",
    "    post_pi_n = NUTSPosteriorSampler.load(NUTS_POSTERIOR_PATH)\n",
    "    post_pi_n.fit(G, transform_out_, noise_sampler, data)\n",
    "\n",
    "post_pi_n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f5aedcc-4661-4647-8a66-c072cc649858",
   "metadata": {},
   "source": [
    "mean_autocorr_time = int(post_pi_n.get_autocorr_time().mean())\n",
    "print(mean_autocorr_time)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d71010bd-b5aa-44b8-938d-a5506cd488d9",
   "metadata": {},
   "source": [
    "post_pi_n.shuffle_samples_cache(thin=int(mean_autocorr_time / 10))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15f68861-35e0-4579-ba09-aa3db54f2436",
   "metadata": {},
   "source": [
    "n_rows, n_cols = 6, 12\n",
    "max_imgs = n_rows * n_cols\n",
    "fig, ax = plotters.plot_list_of_draws(\n",
    "    post_pi_n.rvs(max_imgs), \n",
    "    n_rows=n_rows, n_cols=n_cols,\n",
    "    title=f\"Samples from the MCMC\"\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96d7b561-ba2c-4981-88a8-436bd64c45b6",
   "metadata": {},
   "source": [
    "if SAVE_FIGS:\n",
    "    PATH_TO_SAVE = IMGS_PATH / f\"{post_pi_n.__class__.__name__}-{n_rows}x{n_cols}\"\n",
    "    fig.savefig(PATH_TO_SAVE.with_suffix(\".pdf\"))\n",
    "    fig.savefig(PATH_TO_SAVE.with_suffix(\".png\"))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cec1f1-2733-4c7a-a8dd-957766212109",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
