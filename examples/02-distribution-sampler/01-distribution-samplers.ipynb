{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ecd3527-3304-49df-8e19-a2643dbb711c",
   "metadata": {},
   "source": [
    "# Constantes y Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1220d9ee-0c84-4487-ad07-82b6af5e6425",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# %cd ~/codeProjects/pythonProjects/Bayesian-Learning-with-Wasserstein-Barycenters"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b88a01-d00d-4602-aa7d-5becdd03ef78",
   "metadata": {},
   "source": [
    "SAVE_FIGS = True  # If you want to save the figures."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d4b145-37d1-47e2-b9f9-46e8de44075e",
   "metadata": {},
   "source": [
    "import torch\n",
    "import bwb.plotters as plotters"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b79cac2-228d-42c1-9527-f4e9207ec19a",
   "metadata": {},
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65560e8c-c1b0-4592-b7f3-bd9e8157d81a",
   "metadata": {},
   "source": [
    "from bwb import _logging as logging\n",
    "\n",
    "log = logging.get_logger(__name__)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6525dac6-1cda-4eff-aaf9-d908468ab724",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CURR_PATH = Path().absolute()\n",
    "print(f\"{CURR_PATH = }\")\n",
    "BASE_PATH = CURR_PATH.parent.parent\n",
    "print(f\"{BASE_PATH = }\")\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "print(f\"{DATA_PATH = }\")\n",
    "NETS_PATH = BASE_PATH / \"wgan_gp\" / \"networks\" \n",
    "print(f\"{NETS_PATH = }\")\n",
    "IMGS_PATH = CURR_PATH / \"imgs\" / \"notebook-01\"\n",
    "IMGS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"{IMGS_PATH = }\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a5682796-b013-47f7-a260-7c6a54948591",
   "metadata": {},
   "source": [
    "# Sampleador de Distribuciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f44dc9-d739-4366-86d4-435af0f9200d",
   "metadata": {},
   "source": [
    "La clase padre de todos los muestreadores de distribuciones es el `DistributionSampler`. Básicamente, este define los siguientes métodos:\n",
    "* `draw(seed=None) -> Distribution`: Muestrea una distribución. Si `seed=None` no se utiliza la semilla. Es un método abstracto que se tiene que sobre-escribir.\n",
    "* `rvs(size=1, seed=None) -> Sequence[Distribution]`: Muestrea una secuencia de distribuciones de tamaño `size`. Si `seed=None` no se utiliza la semilla. Es un método abstracto que se tiene que sobre-escribir.\n",
    "* `save(filename)`: Método que salva el muestreador en el archivo `filename`.\n",
    "* `load(filename) -> Self`: Método que carga el muestreador en el archivo `filename`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a50588-8dd4-411d-ad71-1961bb6d3fc7",
   "metadata": {},
   "source": [
    "## Distribuciones Discretas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f83b2ba-ad32-4f28-b0a0-c9f0da103eb4",
   "metadata": {},
   "source": [
    "Muestreador de Distribuciones a soporte discreto. Usualmente necesitan un conjunto de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5977e18-6e02-4756-8e9b-2cb9fd7d2a44",
   "metadata": {},
   "source": [
    "Un ejemplo sería utilizar un dataset como conjunto de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b0c789e-4a3d-4562-844e-dd434ace9cd1",
   "metadata": {},
   "source": [
    "from quick_torch import QuickDraw\n",
    "import torchvision.transforms.v2 as T\n",
    "from pathlib import Path\n",
    "\n",
    "transforms = T.Compose([\n",
    "    T.ToImage(),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Lambda(lambda x: x.squeeze()),\n",
    "])\n",
    "\n",
    "ds = QuickDraw(\n",
    "    DATA_PATH,\n",
    "    categories=\"face\",\n",
    "    download=True,\n",
    "    transform=transforms,\n",
    ")\n",
    "\n",
    "# You can use the wrapper to transform the usual DataSet into a model set\n",
    "from bwb.distributions.models import DiscreteModelsSetP, ModelDataset\n",
    "\n",
    "ds = ModelDataset(ds)\n",
    "\n",
    "print(f\"{isinstance(ds, DiscreteModelsSetP) = }\")\n",
    "\n",
    "_ = plotters.plot_draw(ds.get(0), title=\"First face\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18544f50-f772-4fe0-8fa0-934ee9f907ee",
   "metadata": {},
   "source": [
    "from bwb.distributions.distribution_samplers import UniformDiscreteSampler\n",
    "\n",
    "dist_sampler = UniformDiscreteSampler().fit(ds)\n",
    "dist_sampler"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ce8712-249c-47ea-85d8-012577bc72c0",
   "metadata": {},
   "source": [
    "_ = plotters.plot_draw(dist_sampler.draw(), title=\"Random sample from dataset\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b8a7bba-0a45-48b2-a560-b06dad13e74e",
   "metadata": {},
   "source": [
    "n_rows, n_cols = 6, 12\n",
    "max_imgs = n_rows * n_cols\n",
    "fig, ax = plotters.plot_list_of_draws(\n",
    "    dist_sampler.rvs(max_imgs), \n",
    "    n_rows=n_rows, n_cols=n_cols,\n",
    "    title=f\"Samples from the dataset\"\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6421481a-d6c4-4f0c-9cbd-b9cdee59d7b5",
   "metadata": {},
   "source": [
    "if SAVE_FIGS:\n",
    "    PATH_TO_SAVE = IMGS_PATH / f\"{dist_sampler.__class__.__name__}-{n_rows}x{n_cols}\"\n",
    "    fig.savefig(PATH_TO_SAVE.with_suffix(\".pdf\"))\n",
    "    fig.savefig(PATH_TO_SAVE.with_suffix(\".png\"))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e695077a-6c1f-4dbe-8d44-e939ab04e0e3",
   "metadata": {},
   "source": [
    "También existe la clase `bwb.distributions.posterior_samplers.ExplicitPosteriorSampler`, que es un sampler a soporte discreto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c3cc61-f03d-4799-af6b-94eb8e1f97f4",
   "metadata": {},
   "source": [
    "## Distribuciones Continuas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2331fd1a-55bb-4ae5-94a9-a039a1ebe903",
   "metadata": {},
   "source": [
    "Distribuciones que tienen un soporte continuo. En este caso, heredan de la clase `bwb.distributions.distribution_samplers.ContinuousDistribSampler`. Dentro del cuál, el más destacable es la clase abstracta `bwb.distributions.distribution_samplers.BaseGeneratorDistribSampler`.\n",
    "\n",
    "Para utilizarlo, es necesario utilizar un generador (que puede ser una red neuronal), un transformador (para que lo interprete como un vector de probabilidad) y un muestreador de ruido (para samplear ruido latente $z$, tipicamente de una normal).\n",
    "\n",
    "En la siguiente celda se importa una red neuronal `G` y un sampleador de ruido `noise_sampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029d850e-3807-4b4b-871e-a3e85c2aa322",
   "metadata": {},
   "source": [
    "from wgan_gp.wgan_gp_vae.model_resnet import Generator, Encoder, LatentDistribution\n",
    "import torch\n",
    "from wgan_gp.wgan_gp_vae.utils import load_checkpoint\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "NOISE = \"norm\"\n",
    "LATENT_DIM = 128\n",
    "CHANNELS_IMG = 1\n",
    "NUM_FILTERS = [256, 128, 64, 32]\n",
    "\n",
    "noise_sampler = LatentDistribution(NOISE, LATENT_DIM, device)\n",
    "\n",
    "G = Generator(LATENT_DIM, CHANNELS_IMG, latent_distr=NOISE).to(device)\n",
    "E = Encoder(LATENT_DIM, CHANNELS_IMG).to(device)\n",
    "\n",
    "DS_NAME = \"data\"\n",
    "FACE_PATH = NETS_PATH / f\"cleaned_{DS_NAME}_zDim{LATENT_DIM}_{NOISE}_bs_128\"\n",
    "\n",
    "load_checkpoint(G, FACE_PATH, \"generator\", device)\n",
    "load_checkpoint(E, FACE_PATH, \"encoder\", device)\n",
    "\n",
    "G.eval(); E.eval()\n",
    "print()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0ebef8eb-59ac-4169-8d6f-c545afcc60b0",
   "metadata": {},
   "source": [
    "Y en la siguiente celda se define una transformación para la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b808f27-170f-4d61-8d27-d56d03d9c7f0",
   "metadata": {},
   "source": [
    "from bwb.distributions import DistributionDraw\n",
    "from torchvision import disable_beta_transforms_warning\n",
    "disable_beta_transforms_warning()\n",
    "\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "\n",
    "z = noise_sampler(1)\n",
    "m = G(z)\n",
    "\n",
    "transform_in = T.Compose([\n",
    "    T.Lambda(lambda x: x / torch.max(x)),\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(32),\n",
    "    T.ToImage(),\n",
    "    T.ConvertImageDtype(torch.float32),\n",
    "    T.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "transform_out_ = T.Compose([\n",
    "    T.ToDtype(torch.float64),\n",
    "    T.Lambda(lambda x: x.squeeze()),\n",
    "    T.Lambda(lambda x: x - torch.min(x)),\n",
    "    T.Lambda(lambda x: x / torch.sum(x)),\n",
    "])\n",
    "\n",
    "transform_out = T.Compose([\n",
    "    transform_out_,\n",
    "    T.Lambda(lambda x: DistributionDraw.from_grayscale_weights(x)),\n",
    "])\n",
    "\n",
    "out: DistributionDraw = transform_out(m)\n",
    "print(out.dtype)\n",
    "out"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7d038e6f-598e-4d75-94cb-3b765c368514",
   "metadata": {},
   "source": [
    "Definimos la distribución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9782c8d4-48f3-48d9-b7ac-708c8bdfd2d0",
   "metadata": {},
   "source": [
    "from bwb.distributions.distribution_samplers import GeneratorDistribSampler\n",
    "\n",
    "dist_sampler = GeneratorDistribSampler().fit(generator=G, transform_out=transform_out_, noise_sampler=noise_sampler)\n",
    "dist_sampler"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90693090-8761-441a-aded-01d0b9bb2333",
   "metadata": {},
   "source": [
    "_ = plotters.plot_draw(dist_sampler.draw(), title=\"Random sample from generator\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec4b4bda-8281-46a3-a98a-a1c82023ab6c",
   "metadata": {},
   "source": [
    "import bwb.plotters as plotters\n",
    "\n",
    "n_rows, n_cols = 6, 12\n",
    "max_imgs = n_rows * n_cols\n",
    "fig, ax = plotters.plot_list_of_draws(\n",
    "    dist_sampler.rvs(max_imgs), \n",
    "    n_rows=n_rows, n_cols=n_cols,\n",
    "    title=f\"Samples from the generator\"\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e710582f-0cea-40d2-b683-e9b044b16394",
   "metadata": {},
   "source": [
    "if SAVE_FIGS:\n",
    "    PATH_TO_SAVE = IMGS_PATH / f\"{dist_sampler.__class__.__name__}-{n_rows}x{n_cols}\"\n",
    "    fig.savefig(PATH_TO_SAVE.with_suffix(\".pdf\"))\n",
    "    fig.savefig(PATH_TO_SAVE.with_suffix(\".png\"))"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
